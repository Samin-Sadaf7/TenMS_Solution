{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "281f0c86",
   "metadata": {},
   "outputs": [],
   "source": [
    "import fitz  # PyMuPDF\n",
    "import re\n",
    "from langdetect import detect\n",
    "from typing import List,Tuple\n",
    "import pandas as pd\n",
    "from IPython.display import display, Image "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "5362599a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PDF Path: ../data/HSC26-Bangla1st-Paper.pdf\n",
      "Chunk Size: 150 words\n",
      "Overlap: 50 words\n",
      "Model: sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2\n"
     ]
    }
   ],
   "source": [
    "# Configuration\n",
    "PDF_PATH = \"../data/HSC26-Bangla1st-Paper.pdf\"     #PDF Path\n",
    "COLLECTION_NAME = \"bangla_book\"\n",
    "CHUNK_SIZE = 150  # words\n",
    "CHUNK_OVERLAP = 50  # words\n",
    "MODEL_NAME = \"sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2\"\n",
    "\n",
    "print(f\"PDF Path: {PDF_PATH}\")\n",
    "print(f\"Chunk Size: {CHUNK_SIZE} words\")\n",
    "print(f\"Overlap: {CHUNK_OVERLAP} words\")\n",
    "print(f\"Model: {MODEL_NAME}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "8d371c7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Text cleaning functions\n",
    "def clean_extracted_text(text: str) -> str:\n",
    "    \"\"\"Clean and normalize extracted text\"\"\"\n",
    "    # Remove extra whitespaces\n",
    "    text = re.sub(r'\\s+', ' ', text)\n",
    "    \n",
    "    # Remove page numbers and headers/footers\n",
    "    lines = text.split('\\n')\n",
    "    cleaned_lines = []\n",
    "    \n",
    "    for line in lines:\n",
    "        line = line.strip()\n",
    "        # Skip very short lines that might be page numbers or artifacts\n",
    "        if len(line) > 3 and not line.isdigit():\n",
    "            cleaned_lines.append(line)\n",
    "    \n",
    "    text = ' '.join(cleaned_lines)\n",
    "    \n",
    "    # Normalize Bangla punctuation\n",
    "    text = re.sub(r'[‡•§]{2,}', '‡•§', text)\n",
    "    \n",
    "    return text.strip()      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "49f65678",
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_language_segments(text: str) -> List[Tuple[str, str]]:\n",
    "    \"\"\"Detect language segments in mixed Bangla-English text\"\"\"\n",
    "    # Split by sentences using both Bangla and English sentence endings\n",
    "    sentences = re.split(r'[‡•§.!?]+', text)\n",
    "    segments = []\n",
    "    \n",
    "    for sentence in sentences:\n",
    "        sentence = sentence.strip()\n",
    "        if len(sentence) < 5:  # Skip very short segments\n",
    "            continue\n",
    "            \n",
    "        try:\n",
    "            # Detect language\n",
    "            lang = detect(sentence)\n",
    "            # Map language codes\n",
    "            if lang == 'bn':\n",
    "                lang = 'bangla'\n",
    "            elif lang == 'en':\n",
    "                lang = 'english'\n",
    "            else:\n",
    "                lang = 'mixed'\n",
    "                \n",
    "            segments.append((sentence, lang))\n",
    "        except:\n",
    "            # If detection fails, mark as mixed\n",
    "            segments.append((sentence, 'mixed'))\n",
    "    \n",
    "    return segments\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "feaa6da2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting text from: ../data/HSC26-Bangla1st-Paper.pdf\n",
      "Extracted text from 49 pages\n"
     ]
    }
   ],
   "source": [
    "# Extract text from PDF\n",
    "print(f\"Extracting text from: {PDF_PATH}\")\n",
    "\n",
    "doc = fitz.open(PDF_PATH)\n",
    "pages_data = []\n",
    "\n",
    "for page_num in range(len(doc)):\n",
    "    page = doc.load_page(page_num)\n",
    "    text = page.get_text()\n",
    "    \n",
    "    # Clean extracted text\n",
    "    text = clean_extracted_text(text)\n",
    "    \n",
    "    if text.strip():  # Only add non-empty pages\n",
    "        pages_data.append({\n",
    "            'page_number': page_num + 1,\n",
    "            'text': text,\n",
    "            'word_count': len(text.split())\n",
    "        })\n",
    "\n",
    "doc.close()\n",
    "\n",
    "print(f\"Extracted text from {len(pages_data)} pages\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "fc2c2272",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Sample from Page 1 (14 words):\n",
      "'‡¶Ö‡¶®‡¶≤‡¶æ‡¶á‡¶® ‡¶¨‡ßç‡¶Ø‡¶æ‡¶ö ‡¶∏‡¶Æ‡ßç‡¶™‡¶∞‡ßç‡¶ï‡¶ø‡¶§ ‡¶Ø‡ßá‡¶ï‡¶ï‡¶æ‡¶ï‡¶®‡¶æ ‡¶ú‡¶ø‡¶ú‡ßç‡¶û‡¶æ‡¶æ‡¶∏‡¶æ , ‡¶Ö‡¶™‡¶∞‡¶ø‡¶∞‡¶ø‡¶§‡¶æ ‡¶Ü‡¶≤ ‡¶æ‡¶ø‡¶Ø ‡¶∞‡¶ø‡¶∑‡ßü ‡¶ø‡¶æ‡¶æ‡¶Ç ‡¶æ ‡ßß‡¶Æ ‡¶™‡¶§‡ßç‡¶∞...'\n"
     ]
    }
   ],
   "source": [
    "# Display sample page\n",
    "if pages_data:\n",
    "    sample_page = pages_data[0]\n",
    "    print(f\"\\nSample from Page {sample_page['page_number']} ({sample_page['word_count']} words):\")\n",
    "    print(f\"'{sample_page['text'][:200]}...'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "2d007d72",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Content Analysis:\n",
      "   Total Pages: 49\n",
      "   Total Words: 7261\n",
      "   Average Words per Page: 148.2\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>page_number</th>\n",
       "      <th>text</th>\n",
       "      <th>word_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>‡¶Ö‡¶®‡¶≤‡¶æ‡¶á‡¶® ‡¶¨‡ßç‡¶Ø‡¶æ‡¶ö ‡¶∏‡¶Æ‡ßç‡¶™‡¶∞‡ßç‡¶ï‡¶ø‡¶§ ‡¶Ø‡ßá‡¶ï‡¶ï‡¶æ‡¶ï‡¶®‡¶æ ‡¶ú‡¶ø‡¶ú‡ßç‡¶û‡¶æ‡¶æ‡¶∏‡¶æ , ‡¶Ö‡¶™...</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>‡ßß‡•§ ‡¶Ö‡¶®‡ßÅ‡¶™‡¶≤‡ßá‡¶ø ‡¶ø‡¶æ‡¶ø‡¶æ ‡¶ï‡ßÄ ‡¶ï‡¶≤‡¶ø ‡¶ú‡ßÄ‡¶∞‡¶ø‡¶ï‡¶æ ‡¶∞‡¶®‡¶ø‡¶¨‡¶æ‡¶π ‡¶ï‡¶ø‡¶≤‡¶§‡¶®? ‡¶ï)...</td>\n",
       "      <td>202</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>‡¶∂‡¶¨‡ßç‡¶¶‡¶æ‡¶∞‡ßç‡¶¨ ‡¶ì ‡¶ü‡ßÄ‡¶ï‡¶æ ‡ßá‡ßÇ ‡¶∂‡¶¨‡ßç‡¶¶ ‡¶∂‡¶≤‡¶¨‡ßç‡¶¶‡¶ø ‡¶Ö‡¶∞‡ßç‡¶¨ ‡¶ì ‡¶ø‡¶Ø‡¶æ‡¶ñ‡ßç‡¶Ø‡¶æ ...</td>\n",
       "      <td>271</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>‡¶∂‡¶¨‡ßç‡¶¶‡¶æ‡¶∞‡ßç‡¶¨ ‡¶ì ‡¶ü‡ßÄ‡¶ï‡¶æ ‡ßá‡ßÇ ‡¶∂‡¶¨‡ßç‡¶¶ ‡¶∂‡¶≤‡¶¨‡ßç‡¶¶‡¶ø ‡¶Ö‡¶∞‡ßç‡¶¨ ‡¶ì ‡¶ø‡¶Ø‡¶æ‡¶ñ‡ßç‡¶Ø‡¶æ ...</td>\n",
       "      <td>210</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>‡¶∂‡¶¨‡ßç‡¶¶‡¶æ‡¶∞‡ßç‡¶¨ ‡¶ì ‡¶ü‡ßÄ‡¶ï‡¶æ ‡ßá‡ßÇ ‡¶∂‡¶¨‡ßç‡¶¶ ‡¶∂‡¶≤‡¶¨‡ßç‡¶¶‡¶ø ‡¶Ö‡¶∞‡ßç‡¶¨ ‡¶ì ‡¶ø‡¶Ø‡¶æ‡¶ñ‡ßç‡¶Ø‡¶æ ...</td>\n",
       "      <td>72</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>‡ßá‡ßÇ ‡¶ó‡ßç‡ßá ‡¶Ü‡¶ø‡¶Ü‡¶Æ‡¶æ‡¶ø‡¶¨‡ßç ‡¶∏‡¶∏‡¶æ‡¶§‡¶æ‡¶ø‡¶Æ‡¶æ‡¶§‡ßç‡¶∞‡•§‡¶è‡¶ø‡ßÄ‡¶¨‡ßç‡¶®‡¶ü‡¶æ‡¶®‡¶æ‡¶¶‡¶¶‡¶ï‡¶ò‡¶ø‡¶Ø‡¶ø‡¶∞...</td>\n",
       "      <td>112</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>‡¶Ü‡¶Æ‡¶æ‡¶ø‡¶π‡¶∞‡ßç‡¶ø‡¶ø‡¶ï‡¶æ‡¶®‡¶™‡ßÅ‡¶ï‡¶ø‡¶ï‡¶æ‡¶ø‡¶ï‡¶ï‡¶ø‡•§‡¶Ø‡¶∏‡¶ø‡ßÅ‡¶ü‡¶ø‡¶ï‡¶§‡¶ï‡¶ú‡¶≤‡¶ï‡¶æ‡¶§‡¶æ ‡¶Ü‡¶∞‡ßç‡¶∏ ‡¶æ‡¶Ü...</td>\n",
       "      <td>120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>‚Äú‡¶Æ‡¶®‡ßç‡¶¶‡¶® ‡¶Ø‡¶π! ‡¶ñ‡¶æ‡¶ü‡¶ø‡¶Ø‡¶∏‡¶æ‡¶®‡¶æ ‡¶¨‡ßç‡¶ï‡¶ü!‚Äù ‡¶∞‡ßç‡¶¨‡ßç‡¶®‡ßÅ‡¶¶‡¶æ‡¶¶‡¶æ‡¶ø‡¶≠‡¶æ‡¶∑‡¶æ‡¶ü‡¶æ‡¶Ö...</td>\n",
       "      <td>143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>‡¶Æ‡¶æ‡¶Æ‡¶æ‡¶∞‡ßç‡¶¨‡ßç‡¶¨‡ßç‡¶æ‡¶π-‡¶¨‡ßç‡¶æ‡¶∞‡ßç‡¶º‡ßá‡¶ï‡¶§ ‡ßÅ‡¶∞‡ßç‡¶ï ‡¶æ‡¶ñ‡ßÅ‡¶∞‡ßç‡¶ø‡¶π‡¶á‡¶ï‡¶≤‡¶®‡¶®‡¶æ‡•§‡¶è‡¶ï‡¶ï‡¶Ø...</td>\n",
       "      <td>121</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>‡¶è‡¶á‡¶¨‡ßç‡¶ú‡¶≤ ‡¶æ‡¶Ø‡ßá‡¶Æ‡¶ï‡¶ø‡¶Æ‡ßÅ‡¶ñ‡¶æ‡¶Ø‡¶Æ‡¶æ‡¶ü‡¶æ‡¶è‡¶ï‡¶ñ‡¶æ‡¶®‡¶æ‡¶¨‡ßç‡¶æ‡¶≤‡¶æ ‡¶è‡¶ï‡¶ü‡ßÅ‡¶ö‡¶æ‡¶™‡¶∞‡ßç‡¶¶ ‡¶æ...</td>\n",
       "      <td>104</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   page_number                                               text  word_count\n",
       "0            1  ‡¶Ö‡¶®‡¶≤‡¶æ‡¶á‡¶® ‡¶¨‡ßç‡¶Ø‡¶æ‡¶ö ‡¶∏‡¶Æ‡ßç‡¶™‡¶∞‡ßç‡¶ï‡¶ø‡¶§ ‡¶Ø‡ßá‡¶ï‡¶ï‡¶æ‡¶ï‡¶®‡¶æ ‡¶ú‡¶ø‡¶ú‡ßç‡¶û‡¶æ‡¶æ‡¶∏‡¶æ , ‡¶Ö‡¶™...          14\n",
       "1            2  ‡ßß‡•§ ‡¶Ö‡¶®‡ßÅ‡¶™‡¶≤‡ßá‡¶ø ‡¶ø‡¶æ‡¶ø‡¶æ ‡¶ï‡ßÄ ‡¶ï‡¶≤‡¶ø ‡¶ú‡ßÄ‡¶∞‡¶ø‡¶ï‡¶æ ‡¶∞‡¶®‡¶ø‡¶¨‡¶æ‡¶π ‡¶ï‡¶ø‡¶≤‡¶§‡¶®? ‡¶ï)...         202\n",
       "2            3  ‡¶∂‡¶¨‡ßç‡¶¶‡¶æ‡¶∞‡ßç‡¶¨ ‡¶ì ‡¶ü‡ßÄ‡¶ï‡¶æ ‡ßá‡ßÇ ‡¶∂‡¶¨‡ßç‡¶¶ ‡¶∂‡¶≤‡¶¨‡ßç‡¶¶‡¶ø ‡¶Ö‡¶∞‡ßç‡¶¨ ‡¶ì ‡¶ø‡¶Ø‡¶æ‡¶ñ‡ßç‡¶Ø‡¶æ ...         271\n",
       "3            4  ‡¶∂‡¶¨‡ßç‡¶¶‡¶æ‡¶∞‡ßç‡¶¨ ‡¶ì ‡¶ü‡ßÄ‡¶ï‡¶æ ‡ßá‡ßÇ ‡¶∂‡¶¨‡ßç‡¶¶ ‡¶∂‡¶≤‡¶¨‡ßç‡¶¶‡¶ø ‡¶Ö‡¶∞‡ßç‡¶¨ ‡¶ì ‡¶ø‡¶Ø‡¶æ‡¶ñ‡ßç‡¶Ø‡¶æ ...         210\n",
       "4            5  ‡¶∂‡¶¨‡ßç‡¶¶‡¶æ‡¶∞‡ßç‡¶¨ ‡¶ì ‡¶ü‡ßÄ‡¶ï‡¶æ ‡ßá‡ßÇ ‡¶∂‡¶¨‡ßç‡¶¶ ‡¶∂‡¶≤‡¶¨‡ßç‡¶¶‡¶ø ‡¶Ö‡¶∞‡ßç‡¶¨ ‡¶ì ‡¶ø‡¶Ø‡¶æ‡¶ñ‡ßç‡¶Ø‡¶æ ...          72\n",
       "5            6  ‡ßá‡ßÇ ‡¶ó‡ßç‡ßá ‡¶Ü‡¶ø‡¶Ü‡¶Æ‡¶æ‡¶ø‡¶¨‡ßç ‡¶∏‡¶∏‡¶æ‡¶§‡¶æ‡¶ø‡¶Æ‡¶æ‡¶§‡ßç‡¶∞‡•§‡¶è‡¶ø‡ßÄ‡¶¨‡ßç‡¶®‡¶ü‡¶æ‡¶®‡¶æ‡¶¶‡¶¶‡¶ï‡¶ò‡¶ø‡¶Ø‡¶ø‡¶∞...         112\n",
       "6            7  ‡¶Ü‡¶Æ‡¶æ‡¶ø‡¶π‡¶∞‡ßç‡¶ø‡¶ø‡¶ï‡¶æ‡¶®‡¶™‡ßÅ‡¶ï‡¶ø‡¶ï‡¶æ‡¶ø‡¶ï‡¶ï‡¶ø‡•§‡¶Ø‡¶∏‡¶ø‡ßÅ‡¶ü‡¶ø‡¶ï‡¶§‡¶ï‡¶ú‡¶≤‡¶ï‡¶æ‡¶§‡¶æ ‡¶Ü‡¶∞‡ßç‡¶∏ ‡¶æ‡¶Ü...         120\n",
       "7            8  ‚Äú‡¶Æ‡¶®‡ßç‡¶¶‡¶® ‡¶Ø‡¶π! ‡¶ñ‡¶æ‡¶ü‡¶ø‡¶Ø‡¶∏‡¶æ‡¶®‡¶æ ‡¶¨‡ßç‡¶ï‡¶ü!‚Äù ‡¶∞‡ßç‡¶¨‡ßç‡¶®‡ßÅ‡¶¶‡¶æ‡¶¶‡¶æ‡¶ø‡¶≠‡¶æ‡¶∑‡¶æ‡¶ü‡¶æ‡¶Ö...         143\n",
       "8            9  ‡¶Æ‡¶æ‡¶Æ‡¶æ‡¶∞‡ßç‡¶¨‡ßç‡¶¨‡ßç‡¶æ‡¶π-‡¶¨‡ßç‡¶æ‡¶∞‡ßç‡¶º‡ßá‡¶ï‡¶§ ‡ßÅ‡¶∞‡ßç‡¶ï ‡¶æ‡¶ñ‡ßÅ‡¶∞‡ßç‡¶ø‡¶π‡¶á‡¶ï‡¶≤‡¶®‡¶®‡¶æ‡•§‡¶è‡¶ï‡¶ï‡¶Ø...         121\n",
       "9           10  ‡¶è‡¶á‡¶¨‡ßç‡¶ú‡¶≤ ‡¶æ‡¶Ø‡ßá‡¶Æ‡¶ï‡¶ø‡¶Æ‡ßÅ‡¶ñ‡¶æ‡¶Ø‡¶Æ‡¶æ‡¶ü‡¶æ‡¶è‡¶ï‡¶ñ‡¶æ‡¶®‡¶æ‡¶¨‡ßç‡¶æ‡¶≤‡¶æ ‡¶è‡¶ï‡¶ü‡ßÅ‡¶ö‡¶æ‡¶™‡¶∞‡ßç‡¶¶ ‡¶æ...         104"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Analyze extracted content\n",
    "total_words = sum(page['word_count'] for page in pages_data)\n",
    "avg_words_per_page = total_words / len(pages_data) if pages_data else 0\n",
    "\n",
    "print(f\"Content Analysis:\")\n",
    "print(f\"   Total Pages: {len(pages_data)}\")\n",
    "print(f\"   Total Words: {total_words}\")\n",
    "print(f\"   Average Words per Page: {avg_words_per_page:.1f}\")\n",
    "\n",
    "# Create a quick visualization\n",
    "page_stats = pd.DataFrame(pages_data)\n",
    "display(page_stats.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "cb5d5adc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"‡ßß‡•§ ‡¶Ö‡¶®‡ßÅ‡¶™‡¶≤‡ßá‡¶ø ‡¶ø‡¶æ‡¶ø‡¶æ ‡¶ï‡ßÄ ‡¶ï‡¶≤‡¶ø ‡¶ú‡ßÄ‡¶∞‡¶ø‡¶ï‡¶æ ‡¶∞‡¶®‡¶ø‡¶¨‡¶æ‡¶π ‡¶ï‡¶ø‡¶≤‡¶§‡¶®? ‡¶ï) ‡¶°‡¶æ‡¶ï‡ßç‡¶§‡¶æ‡¶∞‡ßç‡¶ø ‡¶ñ) ‡¶ì‡¶ï‡¶æ‡¶≤‡¶∞‡ßç‡¶§ ‡¶ó) ‡¶Æ‡¶æ‡¶∏‡ßç‡¶ü‡¶æ‡¶∞‡ßç‡¶ø ‡¶ò) ‡¶¨‡ßç‡¶Ø‡¶¨‡ßç‡¶∏‡¶æ ‡ß®‡•§ ‡ßá‡¶æ‡ßá‡¶æ‡¶≤‡¶ï ‡¶≠‡¶æ‡¶ó‡ßç‡¶Ø ‡¶¶‡ßá‡¶ø‡¶§‡¶æ‡¶ø ‡¶™‡ßç‡¶∞‡¶ß‡¶æ‡¶® ‡¶è‡¶≤‡¶ú‡¶®‡ßç‡¶ü ‡¶ø ‡¶æ‡¶ø ‡¶ï‡¶æ‡¶ø‡¶£, ‡¶§‡¶æ‡¶ø- ‡¶ï) ‡¶™‡ßç‡¶∞‡¶∞‡ßç‡¶§‡¶™‡¶ú‡¶ø ‡¶ñ) ‡¶™‡ßç‡¶∞‡¶≠‡¶æ‡¶¨‡ßç ‡¶ó) ‡¶∞‡ßç‡¶¨‡ßç‡¶ö‡¶ï‡ßç‡¶∑‡¶£‡¶§‡¶æ ‡¶ò) ‡¶ï‡ßÇ‡¶ü ‡¶¨‡ßç‡ßÅ‡¶∞‡ßç‡¶ø ‡¶∞‡ßç‡¶®‡¶ï‡¶ö‡¶ø ‡¶Ö‡¶®‡ßÅ‡¶ï‡ßá‡¶¶‡¶ü‡¶ø ‡¶™‡¶ï‡¶º‡ßá ‡ß© ‡¶ì ‡ß™ ‡¶∏‡¶Ç‡¶ñ‡¶Ø‡¶ï ‡¶™‡ßç‡¶∞‡¶ï‡ßá‡¶ø ‡¶â‡¶ø‡¶ø ‡¶¶‡¶æ‡¶ì‡•§ ‡¶∞‡ßç‡¶™‡¶§‡ßÉ‡¶π‡ßÄ‡¶® ‡¶¶‡ßÄ‡¶™‡ßÅ‡¶ø ‡¶ö‡¶æ‡¶ö‡¶æ‡¶á ‡¶∞‡ßç‡¶ø‡¶ï‡¶≤‡¶® ‡¶™‡¶∞‡ßç‡¶ø‡¶¨‡ßç‡¶æ‡¶ï‡¶ø‡¶ø ‡¶ï‡¶§‡¶ø‡¶æ‡•§ ‡¶¶‡ßÄ‡¶™‡ßÅ ‡¶∞‡ßç‡¶ø‡¶ú‡¶ï‡ßç‡¶∑‡¶§ ‡¶π‡¶ï‡¶≤‡¶ì ‡¶§‡¶æ‡¶ø ‡¶∞‡ßç‡¶∏‡¶ø‡¶æ‡¶®‡ßç‡¶§ ‡¶Ø‡¶®‡¶ì ‡¶æ‡¶ø ‡¶ï‡ßç‡¶∑‡¶Æ‡¶§‡¶æ ‡¶∞‡ßç‡¶ø‡¶≤ ‡¶®‡¶æ‡•§ ‡¶ö‡¶æ‡¶ö‡¶æ ‡¶§‡¶æ‡¶ø ‡¶∞‡ßç‡¶¨‡ßç‡¶ï ‡¶ø ‡¶â‡¶ï‡¶¶‡¶Ø‡¶æ‡¶ó ‡¶∞‡ßç‡¶®‡¶ï‡¶≤‡¶ì ‡¶Ø‡ßá‡ßå‡¶§‡ßÅ‡¶ï ‡¶∞‡ßç‡¶®‡¶ï ‡¶¨‡ßç‡¶æ‡¶º‡ßá‡¶æ‡¶¨‡ßç‡¶æ‡¶∞‡ßç‡¶º‡ßá ‡¶ï‡¶ø‡¶æ‡¶ø ‡¶ï‡¶æ‡¶ø‡¶ï‡¶£ ‡¶ï‡¶®‡¶Ø‡¶æ‡¶ø ‡¶∞‡ßç‡¶™‡¶§‡¶æ ‡¶Ö‡¶™‡¶Æ‡¶æ‡¶∞‡ßç‡¶®‡¶§ ‡¶Ø‡¶¨‡ßç‡¶æ‡¶ß ‡¶ï‡¶ï‡¶ø ‡¶∞‡ßç‡¶¨‡ßç‡¶ï ‡¶ø ‡¶Ü‡¶ï‡¶≤‡¶æ‡¶ö‡¶®‡¶æ ‡¶Ø‡¶≠‡¶ï‡ßá ‡¶Ø‡¶¶‡¶®‡•§ ‡¶¶‡ßÄ‡¶™‡ßÅ ‡¶Ø‡¶Æ‡¶ï ‡¶ü‡¶ø‡¶ø ‡¶ø‡¶∞‡ßç‡¶¨‡ßç ‡¶Ø‡¶¶‡¶ï‡¶ñ ‡¶Æ‡ßÅ‡¶ó‡ßç‡¶ß ‡¶π‡¶ï‡¶≤‡¶ì ‡¶§‡¶æ‡¶ø ‡¶ö‡¶æ‡¶ö‡¶æ‡¶ï‡¶ï ‡¶∞‡ßç‡¶ï‡¶ø‡ßÅ‡¶á ‡¶¨‡ßç‡¶≤‡¶ï‡¶§ ‡¶™‡¶æ‡¶ï‡¶ø‡¶®‡¶∞‡ßç‡¶®‡•§ ‡ß©‡•§ ‡ßá‡ßÄ‡¶™‡ßÅ‡¶ø ‡¶ø‡¶æ‡¶ø‡¶æ‡¶ø ‡¶∏‡¶≤‡ßá ‚Äò‡¶Ö‡¶™‡¶∞‡¶ø‡¶∞‡¶ø‡¶§‡¶æ' ‡¶ó‡ßç‡¶≤‡ßá‡¶ø ‡¶¶‡¶ï‡¶æ‡¶® ‡¶ø‡¶∞‡¶ø‡¶≤‡ßá‡¶ø ‡¶∞‡ßá ‡¶Ü‡¶≤‡ßá? ‡¶ï) ‡¶π‡¶∞‡ßç‡¶ø‡¶ï‡¶ø‡¶ø ‡¶ñ) ‡¶Æ‡¶æ‡¶Æ‡¶æ‡¶ø ‡¶ó) ‡¶∞‡ßç‡¶ø‡¶ï‡ßç‡¶∑‡¶ï‡¶ï‡¶ø ‡¶ò) ‡¶∞‡ßç‡¶¨‡ßç‡¶®‡ßÅ‡¶ø ‡ß™‡•§ ‡¶â‡¶ï‡ßç‡¶§ ‡¶ø‡¶∞‡¶ø‡¶≤‡ßá ‡¶™‡ßç‡¶∞‡¶æ‡¶ß‡¶æ‡¶®‡¶Ø ‡¶¶‡¶™‡¶≤‡ßü‡¶≤‡ßá - i) ‡¶Ø‡¶¶‡ßå‡¶ø‡¶æ‡¶§‡ßç‡¶Æ ii) ‡¶π‡ßÄ‡¶®‡¶Æ‡ßç‡¶Æ‡¶®‡¶Ø‡¶§‡¶æ iii) ‡¶Ø‡¶≤‡¶æ‡¶≠ ‡¶∞‡ßç‡¶®‡¶ï‡¶ö‡¶ø ‡¶Ø‡¶ï‡¶æ‡¶®‡¶ü‡¶ø ‡¶†‡¶ø‡¶ï? ‡¶ï‡•§ i ‡¶ì ii ‡¶ñ‡•§ ii ‡¶ì iii ‡¶ó‡•§ i ‡¶ì iii ‡¶ò‡•§ i, ii ‡¶ì iii ‡ß´. ‡¶Ö‡¶®‡ßÅ‡¶™‡¶≤‡ßá‡¶ø ‡¶ø‡ßü‡¶∏ ‡¶ï‡¶§ ‡¶ø‡ßá‡¶ø? ‡¶ï) ‡¶™‡¶Å‡¶∞‡ßç‡¶ö‡¶ø ‡¶ñ) ‡¶ø‡¶æ‡¶¨‡ßç‡¶¨‡¶ø‡¶ø ‡¶ó) ‡¶∏‡¶æ‡¶§‡¶æ‡¶ø ‡¶ò) ‡¶Ü‡¶ü‡¶æ‡¶ø ‡¶™‡ßç‡¶∞‡¶æ‡¶ï-‡¶Æ‡ßÇ‡¶≤‡¶Ø‡¶æ ‡¶® ‡¶ï‡¶§‡¶ó‡ßÅ‡¶ï‡¶≤‡¶æ ‡¶™‡ßç‡¶∞‡¶ï‡ßá‡¶ø ‡¶∏‡¶†‡¶ø‡¶ï ‡¶â‡¶ø‡¶ø ‡¶∞‡ßç‡¶¶‡¶ï‡¶§ ‡¶™‡¶æ‡¶ø‡¶ï‡¶≤? SL Ans SL Ans SL Ans SL Ans SL Ans ‡ßß ‡¶ñ ‡ß® ‡¶ó ‡ß© ‡¶ñ ‡ß™ ‡¶ï ‡ß´ ‡¶ó ‚úì‡¶∞‡ßç‡¶®‡¶Æ‡ßç‡¶®‡¶∞‡ßç‡¶¨‡ßç‡¶ø‡¶¨‡ßç‡¶Ø‡¶ú‡¶ï‡ßç‡¶§‡¶ø‡¶π‡¶†‡¶æ‡ßé‡¶∞‡ßç‡¶¨‡ßç‡¶ø‡¶ø‡¶æ‡¶≤‡ßÄ‡¶π‡¶ï ‡¶ì‡¶†‡¶æ‡¶ø‡¶´‡¶ï‡¶≤‡¶∏‡¶Æ‡¶æ‡¶ï‡¶ø‡¶™‡¶∞‡ßç‡¶ø‡¶ö ‡¶∏‡¶Ç‡¶ï‡¶ü‡¶∏‡¶Æ‡ßç‡¶™‡¶ï‡¶ï‡¶ø‡¶ß‡¶æ‡¶ø‡¶£‡¶æ‡¶≤‡¶æ‡¶≠‡¶ï‡¶ø‡¶ï‡¶¨‡ßç‡•§ ‚úì‡¶§‡ßé‡¶ï‡¶æ‡¶≤‡ßÄ‡¶®‡¶∏‡¶Æ‡¶æ‡¶ø-‡¶∏‡¶≠‡¶Ø‡¶§‡¶æ‡¶ì‡¶Æ‡¶æ‡¶®‡¶¨‡ßç‡¶§‡¶æ‡¶ø‡¶Ö‡¶¨‡ßç‡¶Æ‡¶æ‡¶®‡¶®‡¶æ‡¶∏‡¶Æ‡ßç‡¶™‡¶ï‡¶ï‡¶ø‡¶ø‡¶æ‡¶®‡¶ï‡¶§‡¶™‡¶æ‡¶ø‡¶ï‡¶¨‡ßç‡•§ ‚úì‡¶§‡ßé‡¶ï‡¶æ‡¶≤‡ßÄ‡¶®‡¶∏‡¶Æ‡¶æ‡¶ï‡¶ø‡¶ø‡¶™‡¶£‡¶™‡ßç‡¶∞‡¶•‡¶æ‡¶ø‡¶ï‡ßÅ‡¶™‡ßç‡¶∞‡¶≠‡¶æ‡¶¨‡ßç‡¶∏‡¶Æ‡ßç‡¶™‡¶ï‡¶ï‡¶ø‡¶ø‡¶æ‡¶®‡¶ï‡¶§‡¶™‡¶æ‡¶ø‡¶ï‡¶¨‡ßç‡•§ ‚úì‡¶§‡ßé‡¶ï‡¶æ‡¶ï‡¶≤‡¶∏‡¶Æ‡¶æ‡¶ï‡¶ø‡¶≠‡¶¶‡ßç‡¶∞‡¶ï‡¶≤‡¶æ‡¶ï‡¶ï‡¶ø‡¶∏‡ßç‡¶¨‡¶≠‡¶æ‡¶¨‡ßç‡¶¨‡¶¨‡ßç‡¶∞‡ßç‡¶ø‡¶∑‡ßç‡¶ü‡ßç‡¶Ø‡¶∏‡¶Æ‡ßç‡¶™‡¶ï‡¶ï‡¶ø‡¶ú‡ßç‡¶û‡¶æ‡¶æ‡¶®‡¶≤‡¶æ‡¶≠‡¶ï‡¶ø‡¶ï‡¶¨‡ßç‡•§ ‚úì‡¶®‡¶æ‡¶ø‡ßÄ‡¶Ø‡¶ï‡¶æ‡¶Æ‡¶≤‡¶†‡¶ø‡¶ï, ‡¶∞‡ßç‡¶ï‡¶®‡ßç‡¶§‡ßÅ‡¶¶‡ßÅ‡¶¨‡ßç‡¶ø‡¶≤‡¶® - ‡¶ï‡¶≤‡¶Ø‡¶æ‡¶£‡ßÄ‡¶ø‡¶ø‡ßÄ‡¶¨‡ßç‡¶®‡¶ö‡¶∞‡ßç‡¶ø‡¶§‡¶¶‡ßç‡¶¨‡¶æ‡¶ø‡¶æ‡¶™‡ßç‡¶∞‡¶∞‡ßç‡¶§‡¶ú‡¶ø‡¶§‡¶è‡¶á‡¶∏‡¶§‡¶Ø‡¶Ö‡¶®‡ßÅ‡¶ß‡¶æ‡¶¨‡ßç‡¶®‡¶ï‡¶ø‡¶ï‡¶§ ‡¶™‡¶æ‡¶ø‡¶ï‡¶¨‡ßç‡•§ ‚úì‡¶Æ‡¶æ‡¶®‡ßÅ‡¶∑‡¶Ü‡¶ø‡¶æ‡¶∞‡ßç‡¶®‡¶ï ‡¶Ø‡¶¨‡ßç‡¶Å‡¶ï‡¶ö‡¶•‡¶æ‡¶ï‡¶ï- ‡¶Ö‡¶®‡ßÅ‡¶™‡¶ï‡¶Æ‡¶ø‡¶¶‡ßÉ‡¶∑‡ßç‡¶ü‡ßç‡¶æ‡¶ï‡¶®‡ßç‡¶§‡¶Æ‡¶æ‡¶®‡¶¨‡ßç‡¶ø‡ßÄ‡¶¨‡ßç‡¶ï‡¶®‡¶ø‡¶è‡¶á‡¶∞‡ßç‡¶ö‡¶ø‡¶®‡ßç‡¶§‡¶®‡¶∏‡¶§‡¶Ø‡¶¶‡¶ø‡¶®‡¶∏‡¶Æ‡ßç‡¶™‡¶ï‡¶ï‡¶ø ‡¶ú‡ßç‡¶û‡¶æ‡¶æ‡¶®‡¶≤‡¶æ‡¶≠‡¶ï‡¶ø‡¶ï‡¶¨‡ßç‡•§ ‡¶∞‡ßç‡¶ø‡¶ñ‡¶®‡¶´‡¶≤ 2\""
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pages_data[1]['text']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53e6a914",
   "metadata": {},
   "source": [
    "Extracted text is severly corrupted and PyMUDF library fails to recognize the texts correctly. So, better approach is using ocr and extract using Pytesseract"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "d5558216",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "from pdf2image import convert_from_path\n",
    "import cv2\n",
    "import numpy as np\n",
    "import re\n",
    "import pandas as pd\n",
    "from IPython.display import display\n",
    "from PIL import Image\n",
    "import pytesseract"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "16c0f664",
   "metadata": {},
   "outputs": [],
   "source": [
    "TESS_LANG = \"ben\"\n",
    "DPI = 300"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "618c3694",
   "metadata": {},
   "outputs": [],
   "source": [
    "# OCR-based text extraction functions\n",
    "def preprocess_image_for_ocr(image):\n",
    "    \"\"\"Preprocess image for better OCR results\"\"\"\n",
    "    # Convert PIL image to numpy array\n",
    "    img = np.array(image)\n",
    "    \n",
    "    # Convert to grayscale\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)\n",
    "    \n",
    "    # Apply slight Gaussian blur to reduce noise\n",
    "    blurred = cv2.GaussianBlur(gray, (1, 1), 0)\n",
    "    \n",
    "    # Increase contrast\n",
    "    contrast = cv2.convertScaleAbs(blurred, alpha=1.2, beta=10)\n",
    "    \n",
    "    return contrast\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "acc2b59f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_text_tesseract(image: Image.Image) -> str:\n",
    "    \"\"\"Extract Bangla text using Tesseract\"\"\"\n",
    "    return pytesseract.image_to_string(image, lang=TESS_LANG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "a78b8128",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_bangla_text(text: str) -> str:\n",
    "    \"\"\"Clean Bangla OCR output\"\"\"\n",
    "    text = re.sub(r'[^\\u0980-\\u09FF\\s‡•§,!?]', '', text)  # Keep Bangla and punctuation\n",
    "    text = re.sub(r'\\s+', ' ', text)\n",
    "    return text.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "358efc27",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted 49 pages to images\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    # Convert PDF pages to images\n",
    "    images = convert_from_path(PDF_PATH, dpi=DPI) \n",
    "    print(f\"Converted {len(images)} pages to images\")\n",
    "except Exception as e:\n",
    "    print(f\"Error converting PDF: {e}\")\n",
    "    raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "e1cd42fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîç Processing page 1/49... "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ (13 words)\n",
      "üîç Processing page 2/49... "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ (214 words)\n",
      "üîç Processing page 3/49... "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ (163 words)\n",
      "üîç Processing page 4/49... "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ (145 words)\n",
      "üîç Processing page 5/49... "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ (42 words)\n",
      "üîç Processing page 6/49... "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ (318 words)\n",
      "üîç Processing page 7/49... "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ (294 words)\n",
      "üîç Processing page 8/49... "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ (404 words)\n",
      "üîç Processing page 9/49... "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ (264 words)\n",
      "üîç Processing page 10/49... "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ (211 words)\n",
      "üîç Processing page 11/49... "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ (225 words)\n",
      "üîç Processing page 12/49... "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ (372 words)\n",
      "üîç Processing page 13/49... "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ (291 words)\n",
      "üîç Processing page 14/49... "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ (304 words)\n",
      "üîç Processing page 15/49... "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ (347 words)\n",
      "üîç Processing page 16/49... "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ (148 words)\n",
      "üîç Processing page 17/49... "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ (207 words)\n",
      "üîç Processing page 18/49... "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ (219 words)\n",
      "üîç Processing page 19/49... "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ (229 words)\n",
      "üîç Processing page 20/49... "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ (195 words)\n",
      "üîç Processing page 21/49... "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ (326 words)\n",
      "üîç Processing page 22/49... "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ (243 words)\n",
      "üîç Processing page 23/49... "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ (324 words)\n",
      "üîç Processing page 24/49... "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ (328 words)\n",
      "üîç Processing page 25/49... "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ (255 words)\n",
      "üîç Processing page 26/49... "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ (266 words)\n",
      "üîç Processing page 27/49... "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ (244 words)\n",
      "üîç Processing page 28/49... "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ (243 words)\n",
      "üîç Processing page 29/49... "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ (169 words)\n",
      "üîç Processing page 30/49... "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ (273 words)\n",
      "üîç Processing page 31/49... "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ (322 words)\n",
      "üîç Processing page 32/49... "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ (260 words)\n",
      "üîç Processing page 33/49... "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ (247 words)\n",
      "üîç Processing page 34/49... "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ (230 words)\n",
      "üîç Processing page 35/49... "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ (255 words)\n",
      "üîç Processing page 36/49... "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ (258 words)\n",
      "üîç Processing page 37/49... "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ (293 words)\n",
      "üîç Processing page 38/49... "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ (200 words)\n",
      "üîç Processing page 39/49... "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ (128 words)\n",
      "üîç Processing page 40/49... "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ (102 words)\n",
      "üîç Processing page 41/49... "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ (80 words)\n",
      "üîç Processing page 42/49... "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ (305 words)\n",
      "üîç Processing page 43/49... "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ (287 words)\n",
      "üîç Processing page 44/49... "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ (228 words)\n",
      "üîç Processing page 45/49... "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ (356 words)\n",
      "üîç Processing page 46/49... "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ (357 words)\n",
      "üîç Processing page 47/49... "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ (330 words)\n",
      "üîç Processing page 48/49... "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ (227 words)\n",
      "üîç Processing page 49/49... "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ (167 words)\n",
      "\n",
      "‚úÖ Finished OCR on 49 pages\n"
     ]
    }
   ],
   "source": [
    "# OCR all pages\n",
    "pages_data = []\n",
    "for i, image in enumerate(images):\n",
    "    print(f\"üîç Processing page {i+1}/{len(images)}...\", end=\" \")\n",
    "    try:\n",
    "        raw_text = extract_text_tesseract(image)\n",
    "        cleaned_text = clean_bangla_text(raw_text)\n",
    "        if cleaned_text:\n",
    "            pages_data.append({\n",
    "                'page_number': i + 1,\n",
    "                'text': cleaned_text,\n",
    "                'word_count': len(cleaned_text.split()),\n",
    "                'raw_text': raw_text[:300] \n",
    "            })\n",
    "            print(f\"‚úÖ ({len(cleaned_text.split())} words)\")\n",
    "        else:\n",
    "            print(\"‚ö†Ô∏è No text found\")\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Error: {e}\")\n",
    "\n",
    "print(f\"\\n‚úÖ Finished OCR on {len(pages_data)} pages\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "96d7b85b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Summary:\n",
      "   Pages processed: 49\n",
      "   Total words: 11908\n",
      "   Average words per page: 243.0\n"
     ]
    }
   ],
   "source": [
    "# Summary Stats\n",
    "total_words = sum(page['word_count'] for page in pages_data)\n",
    "avg_words = total_words / len(pages_data) if pages_data else 0\n",
    "print(f\"\\n Summary:\")\n",
    "print(f\"   Pages processed: {len(pages_data)}\")\n",
    "print(f\"   Total words: {total_words}\")\n",
    "print(f\"   Average words per page: {avg_words:.1f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "bea03470",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Sample Page 1:\n",
      "Raw OCR: 10940759\n",
      "\n",
      "‡¶Ö‡¶®‡¶≤‡¶æ‡¶á‡¶® ‡¶¨‡ßç‡¶Ø‡¶æ‡¶ü‚Äù\n",
      "\n",
      "‡¶π‡¶ø\n",
      "‡¶¨‡¶æ‡¶Ç‡¶≤‡¶æ * ‡¶á‡¶Ç‡¶∞‡ßá‡¶ú‡¶ø * ‡¶Ü‡¶á‡¶∏‡¶ø‡¶ü‡¶ø\n",
      "\n",
      "‡¶Ö‡¶®‡¶≤‡¶æ‡¶á‡¶® ‡¶¨‡ßç‡¶Ø‡¶æ‡¶ö ‡¶∏‡¶Æ‡ßç‡¶™‡¶∞‡ßç‡¶ï‡¶ø‡¶§ ‡¶Ø‡ßá‡¶ï‡ßã‡¶®‡ßã ‡¶ú‡¶ø‡¶ú‡ßç‡¶û‡¶æ‡¶∏‡¶æ‡¶Ø‡¶º,\n",
      "\n",
      "‡¶ï‡¶≤‡¶ï‡¶∞‡ßã ‡ß¨‡ß¨ 76919\n",
      "\n",
      "Cleaned: ‡¶Ö‡¶®‡¶≤‡¶æ‡¶á‡¶® ‡¶¨‡ßç‡¶Ø‡¶æ‡¶ü ‡¶π‡¶ø ‡¶¨‡¶æ‡¶Ç‡¶≤‡¶æ ‡¶á‡¶Ç‡¶∞‡ßá‡¶ú‡¶ø ‡¶Ü‡¶á‡¶∏‡¶ø‡¶ü‡¶ø ‡¶Ö‡¶®‡¶≤‡¶æ‡¶á‡¶® ‡¶¨‡ßç‡¶Ø‡¶æ‡¶ö ‡¶∏‡¶Æ‡ßç‡¶™‡¶∞‡ßç‡¶ï‡¶ø‡¶§ ‡¶Ø‡ßá‡¶ï‡ßã‡¶®‡ßã ‡¶ú‡¶ø‡¶ú‡ßç‡¶û‡¶æ‡¶∏‡¶æ‡¶Ø‡¶º, ‡¶ï‡¶≤‡¶ï‡¶∞‡ßã ‡ß¨‡ß¨...\n"
     ]
    }
   ],
   "source": [
    "# Display sample page\n",
    "if pages_data:\n",
    "    sample = pages_data[0]\n",
    "    print(f\"\\n Sample Page {sample['page_number']}:\")\n",
    "    print(f\"Raw OCR: {sample['raw_text'][:200]}\")\n",
    "    print(f\"Cleaned: {sample['text'][:200]}...\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "90c890eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create DataFrame for analysis\n",
    "df = pd.DataFrame([{\n",
    "    'page_number': p['page_number'],\n",
    "    'word_count': p['word_count'],\n",
    "    'sample_text': p['text'][:100] + \"...\" if len(p['text']) > 100 else p['text']\n",
    "} for p in pages_data])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "2729ec51",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " First 10 Pages:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>page_number</th>\n",
       "      <th>word_count</th>\n",
       "      <th>sample_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>13</td>\n",
       "      <td>‡¶Ö‡¶®‡¶≤‡¶æ‡¶á‡¶® ‡¶¨‡ßç‡¶Ø‡¶æ‡¶ü ‡¶π‡¶ø ‡¶¨‡¶æ‡¶Ç‡¶≤‡¶æ ‡¶á‡¶Ç‡¶∞‡ßá‡¶ú‡¶ø ‡¶Ü‡¶á‡¶∏‡¶ø‡¶ü‡¶ø ‡¶Ö‡¶®‡¶≤‡¶æ‡¶á‡¶® ‡¶¨‡ßç‡¶Ø...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>214</td>\n",
       "      <td>‡¶≤‡ßÅ‡¶≤ ‡¶ú‡¶Ü‡¶≤‡¶≤‡¶æ‡¶á‡¶® ‡¶¨‡ßç‡¶Ø‡¶æ‡¶ö ‡ßß? ‡¶®‡¶ø‡¶Æ‡ßç‡¶®‡¶¨‡¶ø‡¶§‡ßç‡¶§ ‡¶¨‡ßç‡¶Ø‡¶ï‡ßç‡¶§‡¶ø‡¶∞ ‡¶π‡¶†‡¶æ‡ßé ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>163</td>\n",
       "      <td>‡¶≤‡ßÅ‡¶≤ ‡¶ú‡¶Ü‡¶≤‡¶≤‡¶æ‡¶á‡¶® ‡¶¨‡ßç‡¶Ø‡¶æ‡¶ö ‡ßß? ‡¶ó‡¶≤‡ßç‡¶™‡ßá‡¶∞ ‡¶ï‡¶•‡¶ï ‡¶ö‡¶∞‡¶ø‡¶§‡ßç‡¶∞ ‡¶Ö‡¶®‡ßÅ‡¶™‡¶Æ‡ßá‡¶∞...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>145</td>\n",
       "      <td>‡¶≤‡ßÅ‡¶≤ ‡¶ú‡¶Ü‡¶≤‡¶≤‡¶æ‡¶á‡¶® ‡¶¨‡ßç‡¶Ø‡¶æ‡¶ö ‡ßß? ‡¶¨‡¶ø‡¶ß‡¶æ‡¶®‡¶ï‡¶∞‡ßç‡¶§‡¶æ ‡¶¨‡¶æ ‡¶∂‡¶æ‡¶∏‡ßç‡¶§‡ßç‡¶∞‡¶™‡ßç‡¶∞‡¶£...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>42</td>\n",
       "      <td>‡¶≤‡¶® ‡ßØ ‡¶Ö‡¶®‡¶≤‡¶æ‡¶á‡¶® ‡¶¨‡ßç‡¶Ø‡¶æ‡¶ö ‡¶Æ‡¶æ‡¶ü‡¶ø‡¶∞ ‡¶ñ‡ßã‡¶≤‡ßá‡¶∞ ‡¶¶‡ßÅ‡¶™‡¶æ‡¶∂‡ßá ‡¶ö‡¶æ‡¶Æ‡¶°‡¶º‡¶æ ‡¶≤‡¶æ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>318</td>\n",
       "      <td>‡¶≤‡ßÅ‡¶≤ ‡¶ú‡¶Ü‡¶≤‡¶≤‡¶æ‡¶á‡¶® ‡¶¨‡ßç‡¶Ø‡¶æ‡¶ö ‡ßß? ‡¶Æ‡ßÇ‡¶≤ ‡¶Ü‡¶≤‡ßã‡¶ö‡ßç‡¶Ø ‡¶¨‡¶ø‡¶∑‡¶Ø‡¶º ‡¶Æ‡ßÇ‡¶≤ ‡¶ó‡¶≤‡ßç‡¶™...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>294</td>\n",
       "      <td>‡¶Ü‡¶Æ‡¶æ‡¶∞ ‡¶π‡¶∞‡¶ø‡¶∂ ‡¶ï‡¶æ‡¶®‡¶™‡ßÅ‡¶∞‡ßá ‡¶ï‡¶æ‡¶ú ‡¶ï‡¶∞‡ßá‡•§ ‡¶∏‡ßá ‡¶õ‡ßÅ‡¶ü‡¶ø‡¶§‡ßá ‡¶ï‡¶≤‡¶ø‡¶ï‡¶æ‡¶§‡¶æ‡¶Ø‡¶º...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>404</td>\n",
       "      <td>‡¶Æ‡¶®‡ßç‡¶¶ ‡¶®‡¶Ø‡¶º ‡¶π‡ßá! ‡¶ñ‡¶æ‡¶ü‡¶ø ‡¶∏‡ßã‡¶®‡¶æ ‡¶¨‡¶ü‡ßá! ‡¶¨‡¶ø‡¶®‡ßÅ‡¶¶‡¶æ‡¶¶‡¶æ‡¶∞ ‡¶≠‡¶æ‡¶∑‡¶æ‡¶ü‡¶æ ‡¶Ö...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>264</td>\n",
       "      <td>‡¶≤‡ßÅ‡¶≤ ‡¶ú‡¶Ü‡¶≤‡¶≤‡¶æ‡¶á‡¶® ‡¶¨‡ßç‡¶Ø‡¶æ‡¶ö ‡ßß? ‡¶Æ‡¶æ‡¶Æ‡¶æ ‡¶¨‡¶ø‡¶¨‡¶æ‡¶π‡¶¨‡¶æ‡¶°‡¶º‡¶ø‡¶§‡ßá ‡¶¢‡ßÅ‡¶ï‡¶ø‡¶Ø‡¶º‡¶æ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>211</td>\n",
       "      <td>, ‡¶è‡¶á ‡¶¨‡¶≤‡¶ø‡¶Ø‡¶º‡¶æ ‡¶Ø‡ßá ‡¶Æ‡¶ï‡¶∞‡¶Æ‡ßÅ‡¶ñ‡¶æ ‡¶Æ‡ßã‡¶ü‡¶æ ‡¶è‡¶ï‡¶ñ‡¶æ‡¶®‡¶æ ‡¶¨‡¶æ‡¶≤‡¶æ‡¶Ø‡¶º ‡¶è‡¶ï‡¶ü‡ßÅ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   page_number  word_count                                        sample_text\n",
       "0            1          13  ‡¶Ö‡¶®‡¶≤‡¶æ‡¶á‡¶® ‡¶¨‡ßç‡¶Ø‡¶æ‡¶ü ‡¶π‡¶ø ‡¶¨‡¶æ‡¶Ç‡¶≤‡¶æ ‡¶á‡¶Ç‡¶∞‡ßá‡¶ú‡¶ø ‡¶Ü‡¶á‡¶∏‡¶ø‡¶ü‡¶ø ‡¶Ö‡¶®‡¶≤‡¶æ‡¶á‡¶® ‡¶¨‡ßç‡¶Ø...\n",
       "1            2         214  ‡¶≤‡ßÅ‡¶≤ ‡¶ú‡¶Ü‡¶≤‡¶≤‡¶æ‡¶á‡¶® ‡¶¨‡ßç‡¶Ø‡¶æ‡¶ö ‡ßß? ‡¶®‡¶ø‡¶Æ‡ßç‡¶®‡¶¨‡¶ø‡¶§‡ßç‡¶§ ‡¶¨‡ßç‡¶Ø‡¶ï‡ßç‡¶§‡¶ø‡¶∞ ‡¶π‡¶†‡¶æ‡ßé ...\n",
       "2            3         163  ‡¶≤‡ßÅ‡¶≤ ‡¶ú‡¶Ü‡¶≤‡¶≤‡¶æ‡¶á‡¶® ‡¶¨‡ßç‡¶Ø‡¶æ‡¶ö ‡ßß? ‡¶ó‡¶≤‡ßç‡¶™‡ßá‡¶∞ ‡¶ï‡¶•‡¶ï ‡¶ö‡¶∞‡¶ø‡¶§‡ßç‡¶∞ ‡¶Ö‡¶®‡ßÅ‡¶™‡¶Æ‡ßá‡¶∞...\n",
       "3            4         145  ‡¶≤‡ßÅ‡¶≤ ‡¶ú‡¶Ü‡¶≤‡¶≤‡¶æ‡¶á‡¶® ‡¶¨‡ßç‡¶Ø‡¶æ‡¶ö ‡ßß? ‡¶¨‡¶ø‡¶ß‡¶æ‡¶®‡¶ï‡¶∞‡ßç‡¶§‡¶æ ‡¶¨‡¶æ ‡¶∂‡¶æ‡¶∏‡ßç‡¶§‡ßç‡¶∞‡¶™‡ßç‡¶∞‡¶£...\n",
       "4            5          42  ‡¶≤‡¶® ‡ßØ ‡¶Ö‡¶®‡¶≤‡¶æ‡¶á‡¶® ‡¶¨‡ßç‡¶Ø‡¶æ‡¶ö ‡¶Æ‡¶æ‡¶ü‡¶ø‡¶∞ ‡¶ñ‡ßã‡¶≤‡ßá‡¶∞ ‡¶¶‡ßÅ‡¶™‡¶æ‡¶∂‡ßá ‡¶ö‡¶æ‡¶Æ‡¶°‡¶º‡¶æ ‡¶≤‡¶æ...\n",
       "5            6         318  ‡¶≤‡ßÅ‡¶≤ ‡¶ú‡¶Ü‡¶≤‡¶≤‡¶æ‡¶á‡¶® ‡¶¨‡ßç‡¶Ø‡¶æ‡¶ö ‡ßß? ‡¶Æ‡ßÇ‡¶≤ ‡¶Ü‡¶≤‡ßã‡¶ö‡ßç‡¶Ø ‡¶¨‡¶ø‡¶∑‡¶Ø‡¶º ‡¶Æ‡ßÇ‡¶≤ ‡¶ó‡¶≤‡ßç‡¶™...\n",
       "6            7         294  ‡¶Ü‡¶Æ‡¶æ‡¶∞ ‡¶π‡¶∞‡¶ø‡¶∂ ‡¶ï‡¶æ‡¶®‡¶™‡ßÅ‡¶∞‡ßá ‡¶ï‡¶æ‡¶ú ‡¶ï‡¶∞‡ßá‡•§ ‡¶∏‡ßá ‡¶õ‡ßÅ‡¶ü‡¶ø‡¶§‡ßá ‡¶ï‡¶≤‡¶ø‡¶ï‡¶æ‡¶§‡¶æ‡¶Ø‡¶º...\n",
       "7            8         404  ‡¶Æ‡¶®‡ßç‡¶¶ ‡¶®‡¶Ø‡¶º ‡¶π‡ßá! ‡¶ñ‡¶æ‡¶ü‡¶ø ‡¶∏‡ßã‡¶®‡¶æ ‡¶¨‡¶ü‡ßá! ‡¶¨‡¶ø‡¶®‡ßÅ‡¶¶‡¶æ‡¶¶‡¶æ‡¶∞ ‡¶≠‡¶æ‡¶∑‡¶æ‡¶ü‡¶æ ‡¶Ö...\n",
       "8            9         264  ‡¶≤‡ßÅ‡¶≤ ‡¶ú‡¶Ü‡¶≤‡¶≤‡¶æ‡¶á‡¶® ‡¶¨‡ßç‡¶Ø‡¶æ‡¶ö ‡ßß? ‡¶Æ‡¶æ‡¶Æ‡¶æ ‡¶¨‡¶ø‡¶¨‡¶æ‡¶π‡¶¨‡¶æ‡¶°‡¶º‡¶ø‡¶§‡ßá ‡¶¢‡ßÅ‡¶ï‡¶ø‡¶Ø‡¶º‡¶æ...\n",
       "9           10         211  , ‡¶è‡¶á ‡¶¨‡¶≤‡¶ø‡¶Ø‡¶º‡¶æ ‡¶Ø‡ßá ‡¶Æ‡¶ï‡¶∞‡¶Æ‡ßÅ‡¶ñ‡¶æ ‡¶Æ‡ßã‡¶ü‡¶æ ‡¶è‡¶ï‡¶ñ‡¶æ‡¶®‡¶æ ‡¶¨‡¶æ‡¶≤‡¶æ‡¶Ø‡¶º ‡¶è‡¶ï‡¶ü‡ßÅ..."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Display table\n",
    "print(\"\\n First 10 Pages:\")\n",
    "display(df.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "a49cd34f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Language Classification:\n",
      "   Primarily Bangla pages: 0\n",
      "   Primarily English pages: 0\n",
      "   Mixed content pages: 49\n"
     ]
    }
   ],
   "source": [
    "# Language Classification\n",
    "bangla_pages = 0\n",
    "english_pages = 0\n",
    "mixed_pages = 0\n",
    "\n",
    "for page in pages_data:\n",
    "    text = page['text']\n",
    "    bangla_chars = len(re.findall(r'[‡¶Ö-‡¶î‡¶ã‡¶å‡¶è‡¶ê‡¶ì‡¶î‡¶ï-‡¶π‡ßé‡ßú‡ßù‡ßü‡ß¶-‡ßØ]', text))\n",
    "    english_chars = len(re.findall(r'[a-zA-Z]', text))\n",
    "    total_chars = len(text)\n",
    "\n",
    "    if total_chars > 0:\n",
    "        bangla_ratio = bangla_chars / total_chars\n",
    "        english_ratio = english_chars / total_chars\n",
    "        if bangla_ratio > 0.6:\n",
    "            bangla_pages += 1\n",
    "        elif english_ratio > 0.6:\n",
    "            english_pages += 1\n",
    "        else:\n",
    "            mixed_pages += 1\n",
    "\n",
    "print(f\"\\n Language Classification:\")\n",
    "print(f\"   Primarily Bangla pages: {bangla_pages}\")\n",
    "print(f\"   Primarily English pages: {english_pages}\")\n",
    "print(f\"   Mixed content pages: {mixed_pages}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "e83f5b4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cohere\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import os \n",
    "import faiss \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "3374b61b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HuggingFace Token: hf_al...\n",
      "Cohere Token: d2R8c...\n"
     ]
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "# Access the variables\n",
    "hf_token = os.getenv(\"HF_TOKEN\")\n",
    "cohere_token = os.getenv(\"cohere_api_key\")\n",
    "\n",
    "print(\"HuggingFace Token:\", hf_token[:5] + \"...\" if hf_token else \"Not found\")\n",
    "print(\"Cohere Token:\", cohere_token[:5] + \"...\" if cohere_token else \"Not found\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "bf2bda9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "chunks = []\n",
    "for page in pages_data:\n",
    "    words = page['text'].split()\n",
    "    for i in range(0, len(words), CHUNK_SIZE - CHUNK_OVERLAP):\n",
    "        chunk_words = words[i : i + CHUNK_SIZE]\n",
    "        chunk_text = \" \".join(chunk_words)\n",
    "        chunks.append({\n",
    "            'text': chunk_text,\n",
    "            'page_number': page['page_number']\n",
    "        })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "32ad436d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "146"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(chunks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "e93c1983",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "co = cohere.Client(api_key=cohere_token)\n",
    "# Choose the multilingual model best for Bangla + English\n",
    "EMBED_MODEL = \"embed-multilingual-v3.0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "79a95cc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def embed_texts(texts, input_type=\"search_document\"):\n",
    "    response = co.embed(texts=texts, model=EMBED_MODEL, input_type=input_type)\n",
    "    return np.array(response.embeddings) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "9e9e485d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Embedding chunk texts\n",
    "chunk_texts = [c['text'] for c in chunks]\n",
    "chunk_embeddings = embed_texts(chunk_texts, input_type=\"search_document\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "9fd9bf78",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embedded 146 chunks with shape: (146, 1024)\n"
     ]
    }
   ],
   "source": [
    "print(f\"Embedded {len(chunk_texts)} chunks with shape: {chunk_embeddings.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "2ff09d24",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(146, 1024)\n"
     ]
    }
   ],
   "source": [
    "chunk_embeds = np.array(chunk_embeddings) \n",
    "print(chunk_embeds.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "812fa6d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "dim = chunk_embeds.shape[1]\n",
    "index = faiss.IndexFlatL2(dim) \n",
    "print(index.is_trained)\n",
    "index.add(np.float32(chunk_embeds))  # Ensure embeddings are float32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "cf1a11f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def search(query, top_k=5):\n",
    "    query_emb = embed_texts([query], input_type=\"search_document\")[0]\n",
    "    D, I = index.search(np.float32([query_emb]), top_k)\n",
    "    texts_np = np.array(chunk_texts)\n",
    "    results = pd.DataFrame(data ={\n",
    "        'texts' : texts_np[I[0]],\n",
    "        'distances': D[0]\n",
    "        })\n",
    "    print(f\"Search results for query '{query}':\")\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "44ea3368",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Search results for query '‡¶Ö‡¶®‡ßÅ‡¶™‡¶Æ‡ßá‡¶∞ ‡¶≠‡¶æ‡¶∑‡¶æ‡¶Ø‡¶º ‡¶∏‡ßÅ‡¶™‡ßÅ‡¶∞‡ßÅ‡¶∑ ‡¶ï‡¶æ‡¶ï‡ßá ‡¶¨‡¶≤‡¶æ ‡¶π‡¶Ø‡¶º‡ßá‡¶õ‡ßá?':\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>texts</th>\n",
       "      <th>distances</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>‡ßß‡ß™‡•§ ‡¶Æ‡¶æ‡¶Æ‡¶æ ‡¶ï‡ßá‡¶Æ‡¶® ‡¶ò‡¶∞‡ßá‡¶∞ ‡¶Æ‡ßá‡¶Ø‡¶º‡ßá ‡¶™‡¶õ‡¶®‡ßç‡¶¶ ‡¶ï‡¶∞‡¶§‡ßá‡¶®? ‡¶ï ‡¶ß‡¶®‡ßÄ ‡¶ñ ...</td>\n",
       "      <td>0.870501</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>‡¶ú‡¶ø‡¶ú‡ßç‡¶û‡¶æ‡¶∏‡¶æ ‡¶ï‡¶∞‡¶≤? ‡¶ï ‡¶Ö‡¶®‡ßÅ‡¶™‡¶Æ ‡¶ñ ‡¶Ö‡¶®‡ßÅ‡¶™‡¶Æ‡ßá‡¶∞ ‡¶Æ‡¶æ ‡¶ó ‡¶ú‡ßá‡¶®‡¶æ‡¶∞‡ßá‡¶≤ ‡¶ò...</td>\n",
       "      <td>0.874586</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>‡¶≤‡ßÅ‡¶≤ ‡¶ú‡¶Ü‡¶≤‡¶≤‡¶æ‡¶á‡¶® ‡¶¨‡ßç‡¶Ø‡¶æ‡¶ö ‡ßß? ‡ß©‡ß¶‡•§ ‡¶Ü‡¶Æ‡¶æ‡¶∞ ‡¶Æ‡¶§‡ßã ‡¶Ö‡¶ï‡ßç‡¶∑‡¶Æ ‡¶¶‡ßÅ‡¶®‡¶ø‡¶Ø‡¶º...</td>\n",
       "      <td>0.877187</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>‡¶§‡¶æ‡¶∞ ‡¶™‡ßç‡¶∞‡¶∏‡ßç‡¶§‡¶æ‡¶¨‡ßá ‡¶∏‡¶¨‡¶æ‡¶á ‡¶∏‡¶Æ‡ßç‡¶Æ‡¶§‡¶ø ‡¶¶‡ßá‡¶Ø‡¶º‡•§ ‡¶Ö‡¶®‡ßç‡¶Ø‡¶¶‡¶ø‡¶ï‡ßá ‡¶Ö‡¶™‡¶∞‡¶ø‡¶ö...</td>\n",
       "      <td>0.900062</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>‡¶¶‡ßá‡¶Ø‡¶º‡•§ ‡¶ö‡ßã‡¶ñ‡ßá‡¶∞ ‡¶∏‡¶æ‡¶Æ‡¶®‡ßá ‡¶Ö‡¶®‡ßç‡¶Ø‡¶æ‡¶Ø‡¶º ‡¶¶‡ßá‡¶ñ‡¶≤‡ßá ‡¶á‡¶ö‡ßç‡¶õ‡¶æ ‡¶•‡¶æ‡¶ï‡¶æ ‡¶∏‡¶§‡ßç...</td>\n",
       "      <td>0.915209</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               texts  distances\n",
       "0  ‡ßß‡ß™‡•§ ‡¶Æ‡¶æ‡¶Æ‡¶æ ‡¶ï‡ßá‡¶Æ‡¶® ‡¶ò‡¶∞‡ßá‡¶∞ ‡¶Æ‡ßá‡¶Ø‡¶º‡ßá ‡¶™‡¶õ‡¶®‡ßç‡¶¶ ‡¶ï‡¶∞‡¶§‡ßá‡¶®? ‡¶ï ‡¶ß‡¶®‡ßÄ ‡¶ñ ...   0.870501\n",
       "1  ‡¶ú‡¶ø‡¶ú‡ßç‡¶û‡¶æ‡¶∏‡¶æ ‡¶ï‡¶∞‡¶≤? ‡¶ï ‡¶Ö‡¶®‡ßÅ‡¶™‡¶Æ ‡¶ñ ‡¶Ö‡¶®‡ßÅ‡¶™‡¶Æ‡ßá‡¶∞ ‡¶Æ‡¶æ ‡¶ó ‡¶ú‡ßá‡¶®‡¶æ‡¶∞‡ßá‡¶≤ ‡¶ò...   0.874586\n",
       "2  ‡¶≤‡ßÅ‡¶≤ ‡¶ú‡¶Ü‡¶≤‡¶≤‡¶æ‡¶á‡¶® ‡¶¨‡ßç‡¶Ø‡¶æ‡¶ö ‡ßß? ‡ß©‡ß¶‡•§ ‡¶Ü‡¶Æ‡¶æ‡¶∞ ‡¶Æ‡¶§‡ßã ‡¶Ö‡¶ï‡ßç‡¶∑‡¶Æ ‡¶¶‡ßÅ‡¶®‡¶ø‡¶Ø‡¶º...   0.877187\n",
       "3  ‡¶§‡¶æ‡¶∞ ‡¶™‡ßç‡¶∞‡¶∏‡ßç‡¶§‡¶æ‡¶¨‡ßá ‡¶∏‡¶¨‡¶æ‡¶á ‡¶∏‡¶Æ‡ßç‡¶Æ‡¶§‡¶ø ‡¶¶‡ßá‡¶Ø‡¶º‡•§ ‡¶Ö‡¶®‡ßç‡¶Ø‡¶¶‡¶ø‡¶ï‡ßá ‡¶Ö‡¶™‡¶∞‡¶ø‡¶ö...   0.900062\n",
       "4  ‡¶¶‡ßá‡¶Ø‡¶º‡•§ ‡¶ö‡ßã‡¶ñ‡ßá‡¶∞ ‡¶∏‡¶æ‡¶Æ‡¶®‡ßá ‡¶Ö‡¶®‡ßç‡¶Ø‡¶æ‡¶Ø‡¶º ‡¶¶‡ßá‡¶ñ‡¶≤‡ßá ‡¶á‡¶ö‡ßç‡¶õ‡¶æ ‡¶•‡¶æ‡¶ï‡¶æ ‡¶∏‡¶§‡ßç...   0.915209"
      ]
     },
     "execution_count": 165,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query = \"‡¶Ö‡¶®‡ßÅ‡¶™‡¶Æ‡ßá‡¶∞ ‡¶≠‡¶æ‡¶∑‡¶æ‡¶Ø‡¶º ‡¶∏‡ßÅ‡¶™‡ßÅ‡¶∞‡ßÅ‡¶∑ ‡¶ï‡¶æ‡¶ï‡ßá ‡¶¨‡¶≤‡¶æ ‡¶π‡¶Ø‡¶º‡ßá‡¶õ‡ßá?\"\n",
    "results = search(query, top_k=5)\n",
    "results "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "03e9fc14",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Search results for query '‡¶ï‡¶æ‡¶ï‡ßá ‡¶Ö‡¶®‡ßÅ‡¶™‡¶Æ‡ßá‡¶∞ ‡¶≠‡¶æ‡¶ó‡ßç‡¶Ø ‡¶¶‡ßá‡¶¨‡¶§‡¶æ ‡¶¨‡¶≤‡ßá ‡¶â‡¶≤‡ßç‡¶≤‡ßá‡¶ñ ‡¶ï‡¶∞‡¶æ ‡¶π‡¶Ø‡¶º‡ßá‡¶õ‡ßá?':\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>texts</th>\n",
       "      <th>distances</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>‡¶Ü‡¶®‡¶≤ ‡¶™‡¶æ‡¶†‡ßç‡¶Ø‡¶™‡ßÅ‡¶∏‡ßç‡¶§‡¶ï‡ßá‡¶∞ ‡¶™‡ßç‡¶∞‡¶∂‡ßç‡¶® ‡¶¨‡¶π‡ßÅ‡¶®‡¶ø‡¶∞‡ßç‡¶¨‡¶æ‡¶ö‡¶®‡ßÄ ‡ßß‡•§ ‡¶Ö‡¶®‡ßÅ‡¶™‡¶Æ...</td>\n",
       "      <td>0.693197</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>‡¶™‡ßç‡¶∞‡¶§‡¶ø ‡¶ó ‡¶ß‡¶∞‡¶£‡ßÄ‡¶∞ ‡¶™‡ßç‡¶∞‡¶§‡¶ø ‡ß™‡ß¨‡•§ ‡¶¨‡¶ø‡¶¨‡¶æ‡¶π‡ßá‡¶∞ ‡¶∏‡¶Æ‡¶Ø‡¶º ‡¶Ö‡¶®‡ßÅ‡¶™‡¶Æ‡ßá‡¶∞ ‡¶¨...</td>\n",
       "      <td>0.827196</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>‡¶Ø‡ßå‡¶§‡ßÅ‡¶ï‡¶≤‡ßã‡¶≠‡ßÄ ‡¶ö‡¶∞‡¶ø‡¶§‡ßç‡¶∞‡•§ ‡¶§‡¶ø‡¶®‡¶ø ‡¶Ö‡¶®‡ßÅ‡¶™‡¶Æ‡ßá‡¶∞ ‡¶¨‡¶ø‡¶Ø‡¶º‡ßá‡¶∞ ‡¶ú‡¶®‡ßç‡¶Ø ‡¶è‡¶ï‡¶ü...</td>\n",
       "      <td>0.881034</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>‡¶¨‡¶ø‡¶®‡ßÅ‡•§ ‡¶Ö‡¶ó‡ßç‡¶∞‡¶ú ‡¶ó‡¶£‡ßá‡¶∂ ‡¶ì ‡¶Ö‡¶®‡ßÅ‡¶ú ‡¶ï‡¶æ‡¶∞‡ßç‡¶§‡¶ø‡¶ï‡ßá‡¶Ø‡¶º‡•§ ‡¶¶‡ßá‡¶¨‡ßÄ ‡¶¶‡ßÅ‡¶∞‡ßç‡¶ó...</td>\n",
       "      <td>0.888726</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>‡¶≤‡ßÅ‡¶≤ ‡¶ú‡¶Ü‡¶≤‡¶≤‡¶æ‡¶á‡¶® ‡¶¨‡ßç‡¶Ø‡¶æ‡¶ö ‡ßß? ‡¶ó‡¶≤‡ßç‡¶™‡ßá‡¶∞ ‡¶ï‡¶•‡¶ï ‡¶ö‡¶∞‡¶ø‡¶§‡ßç‡¶∞ ‡¶Ö‡¶®‡ßÅ‡¶™‡¶Æ‡ßá‡¶∞...</td>\n",
       "      <td>0.901505</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               texts  distances\n",
       "0  ‡¶Ü‡¶®‡¶≤ ‡¶™‡¶æ‡¶†‡ßç‡¶Ø‡¶™‡ßÅ‡¶∏‡ßç‡¶§‡¶ï‡ßá‡¶∞ ‡¶™‡ßç‡¶∞‡¶∂‡ßç‡¶® ‡¶¨‡¶π‡ßÅ‡¶®‡¶ø‡¶∞‡ßç‡¶¨‡¶æ‡¶ö‡¶®‡ßÄ ‡ßß‡•§ ‡¶Ö‡¶®‡ßÅ‡¶™‡¶Æ...   0.693197\n",
       "1  ‡¶™‡ßç‡¶∞‡¶§‡¶ø ‡¶ó ‡¶ß‡¶∞‡¶£‡ßÄ‡¶∞ ‡¶™‡ßç‡¶∞‡¶§‡¶ø ‡ß™‡ß¨‡•§ ‡¶¨‡¶ø‡¶¨‡¶æ‡¶π‡ßá‡¶∞ ‡¶∏‡¶Æ‡¶Ø‡¶º ‡¶Ö‡¶®‡ßÅ‡¶™‡¶Æ‡ßá‡¶∞ ‡¶¨...   0.827196\n",
       "2  ‡¶Ø‡ßå‡¶§‡ßÅ‡¶ï‡¶≤‡ßã‡¶≠‡ßÄ ‡¶ö‡¶∞‡¶ø‡¶§‡ßç‡¶∞‡•§ ‡¶§‡¶ø‡¶®‡¶ø ‡¶Ö‡¶®‡ßÅ‡¶™‡¶Æ‡ßá‡¶∞ ‡¶¨‡¶ø‡¶Ø‡¶º‡ßá‡¶∞ ‡¶ú‡¶®‡ßç‡¶Ø ‡¶è‡¶ï‡¶ü...   0.881034\n",
       "3  ‡¶¨‡¶ø‡¶®‡ßÅ‡•§ ‡¶Ö‡¶ó‡ßç‡¶∞‡¶ú ‡¶ó‡¶£‡ßá‡¶∂ ‡¶ì ‡¶Ö‡¶®‡ßÅ‡¶ú ‡¶ï‡¶æ‡¶∞‡ßç‡¶§‡¶ø‡¶ï‡ßá‡¶Ø‡¶º‡•§ ‡¶¶‡ßá‡¶¨‡ßÄ ‡¶¶‡ßÅ‡¶∞‡ßç‡¶ó...   0.888726\n",
       "4  ‡¶≤‡ßÅ‡¶≤ ‡¶ú‡¶Ü‡¶≤‡¶≤‡¶æ‡¶á‡¶® ‡¶¨‡ßç‡¶Ø‡¶æ‡¶ö ‡ßß? ‡¶ó‡¶≤‡ßç‡¶™‡ßá‡¶∞ ‡¶ï‡¶•‡¶ï ‡¶ö‡¶∞‡¶ø‡¶§‡ßç‡¶∞ ‡¶Ö‡¶®‡ßÅ‡¶™‡¶Æ‡ßá‡¶∞...   0.901505"
      ]
     },
     "execution_count": 166,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query = \"‡¶ï‡¶æ‡¶ï‡ßá ‡¶Ö‡¶®‡ßÅ‡¶™‡¶Æ‡ßá‡¶∞ ‡¶≠‡¶æ‡¶ó‡ßç‡¶Ø ‡¶¶‡ßá‡¶¨‡¶§‡¶æ ‡¶¨‡¶≤‡ßá ‡¶â‡¶≤‡ßç‡¶≤‡ßá‡¶ñ ‡¶ï‡¶∞‡¶æ ‡¶π‡¶Ø‡¶º‡ßá‡¶õ‡ßá?\"\n",
    "results = search(query, top_k=5)\n",
    "results "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "e282c3ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Search results for query '‡¶¨‡¶ø‡¶Ø‡¶º‡ßá‡¶∞ ‡¶∏‡¶Æ‡¶Ø‡¶º ‡¶ï‡¶≤‡ßç‡¶Ø‡¶æ‡¶£‡ßÄ‡¶∞ ‡¶™‡ßç‡¶∞‡¶ï‡ßÉ‡¶§ ‡¶¨‡¶Ø‡¶º‡¶∏ ‡¶ï‡¶§ ‡¶õ‡¶ø‡¶≤?':\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>texts</th>\n",
       "      <th>distances</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>‡¶¨‡¶ø‡¶®‡ßÅ‡¶¶‡¶æ‡¶∞ ‡¶ó ‡¶Ö‡¶®‡ßÅ‡¶™‡¶Æ‡ßá‡¶∞ ‡ß´‡ß©‡•§ ‡¶è‡¶ï‡¶¨‡¶æ‡¶∞ ‡¶Æ‡¶æ‡¶Æ‡¶æ‡¶∞ ‡¶ï‡¶æ‡¶õ‡ßá ‡¶ï‡¶•‡¶æ‡¶ü‡¶æ ‡¶™...</td>\n",
       "      <td>0.493747</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>‡¶™‡ßç‡¶∞‡¶§‡¶ø ‡¶ó ‡¶ß‡¶∞‡¶£‡ßÄ‡¶∞ ‡¶™‡ßç‡¶∞‡¶§‡¶ø ‡ß™‡ß¨‡•§ ‡¶¨‡¶ø‡¶¨‡¶æ‡¶π‡ßá‡¶∞ ‡¶∏‡¶Æ‡¶Ø‡¶º ‡¶Ö‡¶®‡ßÅ‡¶™‡¶Æ‡ßá‡¶∞ ‡¶¨...</td>\n",
       "      <td>0.716306</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>‡¶ì ‡ß´ ‡¶Ö‡¶®‡ßÅ‡¶™‡¶Æ‡ßá‡¶∞ ‡¶¨‡¶Ø‡¶º‡¶∏ ‡¶ï‡¶§ ‡¶¨‡¶õ‡¶∞? ‡¶ï ‡¶™‡¶Å‡¶ö‡¶ø‡¶∂ ‡¶ñ ‡¶õ‡¶æ‡¶¨‡¶ø‡¶¨‡¶ø‡¶∂ ‡¶ó ‡¶∏...</td>\n",
       "      <td>0.816529</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>‡¶Æ‡¶®‡ßç‡¶¶ ‡¶®‡¶Ø‡¶º ‡¶π‡ßá! ‡¶ñ‡¶æ‡¶ü‡¶ø ‡¶∏‡ßã‡¶®‡¶æ ‡¶¨‡¶ü‡ßá! ‡¶¨‡¶ø‡¶®‡ßÅ‡¶¶‡¶æ‡¶¶‡¶æ‡¶∞ ‡¶≠‡¶æ‡¶∑‡¶æ‡¶ü‡¶æ ‡¶Ö...</td>\n",
       "      <td>0.819135</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>‡¶≤‡¶® ‡ßØ ‡¶Ö‡¶®‡¶≤‡¶æ‡¶á‡¶® ‡¶¨‡ßç‡¶Ø‡¶æ‡¶ö ‡ß©‡ßØ‡•§ ‡¶è‡¶ñ‡¶æ‡¶®‡ßá ‡¶ú‡¶æ‡¶Ø‡¶º‡¶ó‡¶æ ‡¶Ü‡¶õ‡ßá ‡¶â‡¶ï‡ßç‡¶§‡¶ø‡¶ü‡¶ø...</td>\n",
       "      <td>0.842124</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               texts  distances\n",
       "0  ‡¶¨‡¶ø‡¶®‡ßÅ‡¶¶‡¶æ‡¶∞ ‡¶ó ‡¶Ö‡¶®‡ßÅ‡¶™‡¶Æ‡ßá‡¶∞ ‡ß´‡ß©‡•§ ‡¶è‡¶ï‡¶¨‡¶æ‡¶∞ ‡¶Æ‡¶æ‡¶Æ‡¶æ‡¶∞ ‡¶ï‡¶æ‡¶õ‡ßá ‡¶ï‡¶•‡¶æ‡¶ü‡¶æ ‡¶™...   0.493747\n",
       "1  ‡¶™‡ßç‡¶∞‡¶§‡¶ø ‡¶ó ‡¶ß‡¶∞‡¶£‡ßÄ‡¶∞ ‡¶™‡ßç‡¶∞‡¶§‡¶ø ‡ß™‡ß¨‡•§ ‡¶¨‡¶ø‡¶¨‡¶æ‡¶π‡ßá‡¶∞ ‡¶∏‡¶Æ‡¶Ø‡¶º ‡¶Ö‡¶®‡ßÅ‡¶™‡¶Æ‡ßá‡¶∞ ‡¶¨...   0.716306\n",
       "2  ‡¶ì ‡ß´ ‡¶Ö‡¶®‡ßÅ‡¶™‡¶Æ‡ßá‡¶∞ ‡¶¨‡¶Ø‡¶º‡¶∏ ‡¶ï‡¶§ ‡¶¨‡¶õ‡¶∞? ‡¶ï ‡¶™‡¶Å‡¶ö‡¶ø‡¶∂ ‡¶ñ ‡¶õ‡¶æ‡¶¨‡¶ø‡¶¨‡¶ø‡¶∂ ‡¶ó ‡¶∏...   0.816529\n",
       "3  ‡¶Æ‡¶®‡ßç‡¶¶ ‡¶®‡¶Ø‡¶º ‡¶π‡ßá! ‡¶ñ‡¶æ‡¶ü‡¶ø ‡¶∏‡ßã‡¶®‡¶æ ‡¶¨‡¶ü‡ßá! ‡¶¨‡¶ø‡¶®‡ßÅ‡¶¶‡¶æ‡¶¶‡¶æ‡¶∞ ‡¶≠‡¶æ‡¶∑‡¶æ‡¶ü‡¶æ ‡¶Ö...   0.819135\n",
       "4  ‡¶≤‡¶® ‡ßØ ‡¶Ö‡¶®‡¶≤‡¶æ‡¶á‡¶® ‡¶¨‡ßç‡¶Ø‡¶æ‡¶ö ‡ß©‡ßØ‡•§ ‡¶è‡¶ñ‡¶æ‡¶®‡ßá ‡¶ú‡¶æ‡¶Ø‡¶º‡¶ó‡¶æ ‡¶Ü‡¶õ‡ßá ‡¶â‡¶ï‡ßç‡¶§‡¶ø‡¶ü‡¶ø...   0.842124"
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query = \"‡¶¨‡¶ø‡¶Ø‡¶º‡ßá‡¶∞ ‡¶∏‡¶Æ‡¶Ø‡¶º ‡¶ï‡¶≤‡ßç‡¶Ø‡¶æ‡¶£‡ßÄ‡¶∞ ‡¶™‡ßç‡¶∞‡¶ï‡ßÉ‡¶§ ‡¶¨‡¶Ø‡¶º‡¶∏ ‡¶ï‡¶§ ‡¶õ‡¶ø‡¶≤?\"\n",
    "results = search(query, top_k=5)\n",
    "results "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "7b2882a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from rank_bm25 import BM25Okapi \n",
    "from sklearn.feature_extraction import _stop_words\n",
    "import string "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "d0915b9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def bm25_tokenizer(text):\n",
    "    tokenized_doc = []\n",
    "    for token in text.split():\n",
    "        token = token.strip(string.punctuation)\n",
    "        if token and token not in _stop_words.ENGLISH_STOP_WORDS:\n",
    "            tokenized_doc.append(token.lower())\n",
    "    return tokenized_doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "9f2535eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenizing corpus: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 146/146 [00:00<00:00, 28271.86it/s]\n"
     ]
    }
   ],
   "source": [
    "tokenized_corpus = []\n",
    "for passage in tqdm(chunk_texts, desc=\"Tokenizing corpus\"):\n",
    "    tokenized_corpus.append(bm25_tokenizer(passage))\n",
    "\n",
    "bm25 = BM25Okapi(tokenized_corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "191c7d2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def keyword_search(query, top_k=5,num_candidates=15):\n",
    "    print(\"Input Query:\", query)\n",
    "    bm25_scores = bm25.get_scores(bm25_tokenizer(query))\n",
    "    top_n = np.argpartition(bm25_scores, -num_candidates)[-num_candidates:]\n",
    "    bm25_hits = [{ 'corpus_id': idx, 'score': bm25_scores[idx]} for idx in top_n]\n",
    "    bm25_hits = sorted(bm25_hits, key=lambda x: x['score'], reverse=True)\n",
    "    print(f\"Top {top_k} results for query '{query}':\")\n",
    "    for hit in bm25_hits[:top_k]:\n",
    "        print(f\"  - ID: {hit['corpus_id']}, Score: {hit['score']:.4f}, Text: {chunk_texts[hit['corpus_id']][:100]}...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "e7fa36a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input Query: ‡¶Ö‡¶®‡ßÅ‡¶™‡¶Æ‡ßá‡¶∞ ‡¶≠‡¶æ‡¶∑‡¶æ‡¶Ø‡¶º ‡¶∏‡ßÅ‡¶™‡ßÅ‡¶∞‡ßÅ‡¶∑ ‡¶ï‡¶æ‡¶ï‡ßá ‡¶¨‡¶≤‡¶æ ‡¶π‡¶Ø‡¶º‡ßá‡¶õ‡ßá?\n",
      "Top 5 results for query '‡¶Ö‡¶®‡ßÅ‡¶™‡¶Æ‡ßá‡¶∞ ‡¶≠‡¶æ‡¶∑‡¶æ‡¶Ø‡¶º ‡¶∏‡ßÅ‡¶™‡ßÅ‡¶∞‡ßÅ‡¶∑ ‡¶ï‡¶æ‡¶ï‡ßá ‡¶¨‡¶≤‡¶æ ‡¶π‡¶Ø‡¶º‡ßá‡¶õ‡ßá?':\n",
      "  - ID: 101, Score: 6.8685, Text: ‡¶¨‡¶õ‡¶∞ ‡¶ñ ‡¶™‡ßç‡¶∞‡¶æ‡¶Ø‡¶º ‡¶™‡¶•‡ßç‡¶ó‡¶∂ ‡¶¨‡¶õ‡¶∞ ‡¶ó ‡¶™‡ßç‡¶∞‡¶æ‡¶Ø‡¶º ‡¶∑‡¶æ‡¶ü ‡¶¨‡¶õ‡¶∞ ‡¶ò ‡¶™‡ßç‡¶∞‡¶æ‡¶Ø‡¶º ‡¶∏‡¶§‡ßç‡¶§‡¶∞ ‡¶¨‡¶õ‡¶∞ ‡ß©‡ßß‡•§ ‡¶§‡¶æ‡¶π‡¶æ‡¶∞ ‡¶¨‡¶ø‡¶®‡¶Ø‡¶º‡¶ü‡¶æ ‡¶Ö‡¶ú‡¶∏‡ßç‡¶∞ ‡¶®‡¶Ø‡¶º ‡¶ï‡¶æ‡¶∞? ‡¶ï ‡¶Ö‡¶®‡ßÅ‡¶™‡¶Æ‡ßá...\n",
      "  - ID: 102, Score: 6.8204, Text: ‡¶ó‡¶∞‡ßÅ‡¶∞ ‡¶ó‡¶æ‡¶°‡¶º‡¶ø ‡¶ó ‡¶Æ‡ßã‡¶ü‡¶∞ ‡¶ó‡¶æ‡¶°‡¶º‡¶ø ‡ßØ ‡¶ò ‡¶ò‡ßã‡¶°‡¶º‡¶æ‡¶∞ ‡¶ó‡¶æ‡¶°‡¶º‡¶ø ‡ß©‡ßÆ‡•§ ‡¶Ö‡¶®‡ßç‡¶®‡¶™‡ßÇ‡¶∞‡ßç‡¶£‡¶æ‡¶∞ ‡¶ï‡ßã‡¶≤‡ßá ‡¶ó‡¶ú‡¶æ‡¶®‡¶®‡ßá‡¶∞ ‡¶õ‡ßã‡¶ü ‡¶≠‡¶æ‡¶á‡¶ü‡¶ø ‡¶è‡¶ñ‡¶æ‡¶®‡ßá ‡¶õ‡ßã‡¶ü ‡¶≠‡¶æ‡¶á‡¶ü‡¶ø ‡¶¨‡¶≤‡¶§‡ßá...\n",
      "  - ID: 96, Score: 5.0187, Text: ‡ß¨‡•§ ‡¶Ö‡¶™‡¶∞‡¶ø‡¶ö‡¶ø‡¶§‡¶æ ‡¶ó‡¶≤‡ßç‡¶™‡ßá ‡¶®‡¶æ‡¶Ø‡¶º‡¶ï‡ßá‡¶∞ ‡¶¨‡¶Ø‡¶º‡¶∏ ‡¶ï‡¶§ ‡¶¨‡¶≤‡¶æ ‡¶π‡¶Ø‡¶º‡ßá‡¶õ‡ßá? ‡¶ï ‡ß®‡ßÆ ‡¶¨‡¶õ‡¶∞ ‡¶ñ ‡ß®‡ß¨ ‡¶¨‡¶õ‡¶∞ ‡¶ó ‡ß®‡ß≠ ‡¶¨‡¶õ‡¶∞ ‡¶ò ‡ß®‡ß´ ‡¶¨‡¶õ‡¶∞ ‡ß≠ ‡¶§‡¶¨‡ßÅ ‡¶á‡¶π‡¶æ‡¶∞ ‡¶¨‡¶ø‡¶∂‡ßá‡¶∑ ‡¶Æ...\n",
      "  - ID: 109, Score: 4.9843, Text: ‡¶≤‡ßÅ‡¶≤ ‡¶ú‡¶Ü‡¶≤‡¶≤‡¶æ‡¶á‡¶® ‡¶¨‡ßç‡¶Ø‡¶æ‡¶ö ‡ßß? ‡ß¨‡ßØ‡•§ ‡¶ï‡¶æ‡¶∞ ‡¶∏‡¶ô‡ßç‡¶ó‡ßá ‡¶™‡¶û‡ßç‡¶ö‡¶∂‡¶∞‡ßá‡¶∞ ‡¶¨‡¶ø‡¶∞‡ßã‡¶ß ‡¶®‡ßá‡¶á ‡¶¨‡¶≤‡ßá ‡¶Ö‡¶®‡ßÅ‡¶™‡¶Æ‡ßá‡¶∞ ‡¶Æ‡¶®‡ßá ‡¶π‡¶≤‡ßã? ‡¶ï ‡¶ó‡¶ú‡¶æ‡¶®‡¶®‡ßá‡¶∞ ‡¶ñ ‡¶ï‡¶æ‡¶∞‡ßç‡¶§‡¶ø‡¶ï‡ßá‡¶∞ ‡¶ó ‡¶™...\n",
      "  - ID: 104, Score: 4.8487, Text: ‡¶™‡ßç‡¶∞‡¶§‡¶ø ‡¶ó ‡¶ß‡¶∞‡¶£‡ßÄ‡¶∞ ‡¶™‡ßç‡¶∞‡¶§‡¶ø ‡ß™‡ß¨‡•§ ‡¶¨‡¶ø‡¶¨‡¶æ‡¶π‡ßá‡¶∞ ‡¶∏‡¶Æ‡¶Ø‡¶º ‡¶Ö‡¶®‡ßÅ‡¶™‡¶Æ‡ßá‡¶∞ ‡¶¨‡¶Ø‡¶º‡¶∏ ‡¶ï‡¶§ ‡¶õ‡¶ø‡¶≤? ‡¶ï ‡ß®‡ßß ‡¶¨‡¶õ‡¶∞ ‡¶ñ ‡ß®‡ß© ‡¶¨‡¶õ‡¶∞ ‡¶ó ‡ß®‡ß´ ‡¶¨‡¶õ‡¶∞ ‡ß™‡ß≠‡•§ ‡¶ó‡¶ú‡¶æ‡¶®‡¶®‡ßá‡¶∞ ‡¶Æ‡¶æ‡¶Ø...\n",
      "Input Query: ‡¶ï‡¶æ‡¶ï‡ßá ‡¶Ö‡¶®‡ßÅ‡¶™‡¶Æ‡ßá‡¶∞ ‡¶≠‡¶æ‡¶ó‡ßç‡¶Ø ‡¶¶‡ßá‡¶¨‡¶§‡¶æ ‡¶¨‡¶≤‡ßá ‡¶â‡¶≤‡ßç‡¶≤‡ßá‡¶ñ ‡¶ï‡¶∞‡¶æ ‡¶π‡¶Ø‡¶º‡ßá‡¶õ‡ßá?\n",
      "Top 5 results for query '‡¶ï‡¶æ‡¶ï‡ßá ‡¶Ö‡¶®‡ßÅ‡¶™‡¶Æ‡ßá‡¶∞ ‡¶≠‡¶æ‡¶ó‡ßç‡¶Ø ‡¶¶‡ßá‡¶¨‡¶§‡¶æ ‡¶¨‡¶≤‡ßá ‡¶â‡¶≤‡ßç‡¶≤‡ßá‡¶ñ ‡¶ï‡¶∞‡¶æ ‡¶π‡¶Ø‡¶º‡ßá‡¶õ‡ßá?':\n",
      "  - ID: 104, Score: 18.0485, Text: ‡¶™‡ßç‡¶∞‡¶§‡¶ø ‡¶ó ‡¶ß‡¶∞‡¶£‡ßÄ‡¶∞ ‡¶™‡ßç‡¶∞‡¶§‡¶ø ‡ß™‡ß¨‡•§ ‡¶¨‡¶ø‡¶¨‡¶æ‡¶π‡ßá‡¶∞ ‡¶∏‡¶Æ‡¶Ø‡¶º ‡¶Ö‡¶®‡ßÅ‡¶™‡¶Æ‡ßá‡¶∞ ‡¶¨‡¶Ø‡¶º‡¶∏ ‡¶ï‡¶§ ‡¶õ‡¶ø‡¶≤? ‡¶ï ‡ß®‡ßß ‡¶¨‡¶õ‡¶∞ ‡¶ñ ‡ß®‡ß© ‡¶¨‡¶õ‡¶∞ ‡¶ó ‡ß®‡ß´ ‡¶¨‡¶õ‡¶∞ ‡ß™‡ß≠‡•§ ‡¶ó‡¶ú‡¶æ‡¶®‡¶®‡ßá‡¶∞ ‡¶Æ‡¶æ‡¶Ø...\n",
      "  - ID: 111, Score: 8.6819, Text: ‡¶ï ‡¶™‡¶£‡ßá‡¶∞ ‡¶Ö‡¶ô‡ßç‡¶ï ‡¶∏‡¶æ‡¶Æ‡¶æ‡¶®‡ßç‡¶Ø ‡¶¨‡¶≤‡ßá ‡¶ñ ‡¶Æ‡ßá‡¶Ø‡¶º‡ßá‡¶∞ ‡¶∂‡¶ø‡¶ï‡ßç‡¶∑‡¶æ ‡¶ï‡¶Æ ‡¶¨‡¶≤‡ßá ‡¶ó ‡¶Æ‡ßá‡¶Ø‡¶º‡ßá‡¶∞ ‡¶¨‡¶Ø‡¶º‡¶∏ ‡¶¨‡ßá‡¶∂‡¶ø ‡¶¨‡¶≤‡ßá ‡¶ò ‡¶™‡¶£‡ßá‡¶∞ ‡¶Ö‡¶ô‡ßç‡¶ï ‡¶∏‡¶æ‡¶Æ‡¶æ‡¶®‡ßç‡¶Ø ‡¶¨‡¶≤‡ßá ‡ß≠‡ßØ‡•§ ‡¶ñ‡¶æ...\n",
      "  - ID: 101, Score: 6.8685, Text: ‡¶¨‡¶õ‡¶∞ ‡¶ñ ‡¶™‡ßç‡¶∞‡¶æ‡¶Ø‡¶º ‡¶™‡¶•‡ßç‡¶ó‡¶∂ ‡¶¨‡¶õ‡¶∞ ‡¶ó ‡¶™‡ßç‡¶∞‡¶æ‡¶Ø‡¶º ‡¶∑‡¶æ‡¶ü ‡¶¨‡¶õ‡¶∞ ‡¶ò ‡¶™‡ßç‡¶∞‡¶æ‡¶Ø‡¶º ‡¶∏‡¶§‡ßç‡¶§‡¶∞ ‡¶¨‡¶õ‡¶∞ ‡ß©‡ßß‡•§ ‡¶§‡¶æ‡¶π‡¶æ‡¶∞ ‡¶¨‡¶ø‡¶®‡¶Ø‡¶º‡¶ü‡¶æ ‡¶Ö‡¶ú‡¶∏‡ßç‡¶∞ ‡¶®‡¶Ø‡¶º ‡¶ï‡¶æ‡¶∞? ‡¶ï ‡¶Ö‡¶®‡ßÅ‡¶™‡¶Æ‡ßá...\n",
      "  - ID: 102, Score: 6.8204, Text: ‡¶ó‡¶∞‡ßÅ‡¶∞ ‡¶ó‡¶æ‡¶°‡¶º‡¶ø ‡¶ó ‡¶Æ‡ßã‡¶ü‡¶∞ ‡¶ó‡¶æ‡¶°‡¶º‡¶ø ‡ßØ ‡¶ò ‡¶ò‡ßã‡¶°‡¶º‡¶æ‡¶∞ ‡¶ó‡¶æ‡¶°‡¶º‡¶ø ‡ß©‡ßÆ‡•§ ‡¶Ö‡¶®‡ßç‡¶®‡¶™‡ßÇ‡¶∞‡ßç‡¶£‡¶æ‡¶∞ ‡¶ï‡ßã‡¶≤‡ßá ‡¶ó‡¶ú‡¶æ‡¶®‡¶®‡ßá‡¶∞ ‡¶õ‡ßã‡¶ü ‡¶≠‡¶æ‡¶á‡¶ü‡¶ø ‡¶è‡¶ñ‡¶æ‡¶®‡ßá ‡¶õ‡ßã‡¶ü ‡¶≠‡¶æ‡¶á‡¶ü‡¶ø ‡¶¨‡¶≤‡¶§‡ßá...\n",
      "  - ID: 95, Score: 6.1716, Text: ‡¶∞‡¶¨‡ßÄ‡¶®‡ßç‡¶¶‡ßç‡¶∞‡¶®‡¶æ‡¶• ‡¶†‡¶æ‡¶ï‡ßÅ‡¶∞‡ßá‡¶∞ ‡¶ú‡ßÄ‡¶¨‡¶®‡¶æ‡¶¨‡¶∏‡¶æ‡¶® ‡¶ò‡¶ü‡ßá ‡¶ï‡ßã‡¶•‡¶æ‡¶Ø‡¶º? ‡¶ï ‡¶ú‡ßã‡¶°‡¶º‡¶æ‡¶∏‡¶æ‡¶ï‡ßã‡¶∞ ‡¶†‡¶æ‡¶ï‡ßÅ‡¶∞ ‡¶¨‡¶æ‡¶°‡¶º‡¶ø‡¶§‡ßá ‡¶ñ ‡¶¨‡ßã‡¶≤‡¶™‡ßÅ‡¶∞‡ßá‡¶∞ ‡¶∂‡¶æ‡¶®‡ßç‡¶§‡¶ø‡¶®‡¶ø‡¶ï‡ßá‡¶§‡¶®‡ßá ‡¶ó ‡¶ï‡ßÅ‡¶∑‡ßç...\n",
      "Input Query: ‡¶¨‡¶ø‡¶Ø‡¶º‡ßá‡¶∞ ‡¶∏‡¶Æ‡¶Ø‡¶º ‡¶ï‡¶≤‡ßç‡¶Ø‡¶æ‡¶£‡ßÄ‡¶∞ ‡¶™‡ßç‡¶∞‡¶ï‡ßÉ‡¶§ ‡¶¨‡¶Ø‡¶º‡¶∏ ‡¶ï‡¶§ ‡¶õ‡¶ø‡¶≤?\n",
      "Top 5 results for query '‡¶¨‡¶ø‡¶Ø‡¶º‡ßá‡¶∞ ‡¶∏‡¶Æ‡¶Ø‡¶º ‡¶ï‡¶≤‡ßç‡¶Ø‡¶æ‡¶£‡ßÄ‡¶∞ ‡¶™‡ßç‡¶∞‡¶ï‡ßÉ‡¶§ ‡¶¨‡¶Ø‡¶º‡¶∏ ‡¶ï‡¶§ ‡¶õ‡¶ø‡¶≤?':\n",
      "  - ID: 105, Score: 16.9629, Text: ‡¶¨‡¶ø‡¶®‡ßÅ‡¶¶‡¶æ‡¶∞ ‡¶ó ‡¶Ö‡¶®‡ßÅ‡¶™‡¶Æ‡ßá‡¶∞ ‡ß´‡ß©‡•§ ‡¶è‡¶ï‡¶¨‡¶æ‡¶∞ ‡¶Æ‡¶æ‡¶Æ‡¶æ‡¶∞ ‡¶ï‡¶æ‡¶õ‡ßá ‡¶ï‡¶•‡¶æ‡¶ü‡¶æ ‡¶™‡¶æ‡¶°‡¶º‡¶ø‡¶Ø‡¶º‡¶æ ‡¶¶‡ßá‡¶ñ ‡¶ï‡¶•‡¶æ‡¶ü‡¶ø ‡¶ï‡ßÄ‡¶∏‡ßá‡¶∞? ‡¶ï ‡¶¶‡¶æ‡¶®‡ßá‡¶∞ ‡¶ñ ‡¶ö‡¶æ‡¶ï‡¶∞‡¶ø‡¶∞ ‡¶ó ‡¶¨‡¶ø‡¶Ø‡¶º‡ßá‡¶∞ ‡ß™‡•§ ...\n",
      "  - ID: 104, Score: 15.0718, Text: ‡¶™‡ßç‡¶∞‡¶§‡¶ø ‡¶ó ‡¶ß‡¶∞‡¶£‡ßÄ‡¶∞ ‡¶™‡ßç‡¶∞‡¶§‡¶ø ‡ß™‡ß¨‡•§ ‡¶¨‡¶ø‡¶¨‡¶æ‡¶π‡ßá‡¶∞ ‡¶∏‡¶Æ‡¶Ø‡¶º ‡¶Ö‡¶®‡ßÅ‡¶™‡¶Æ‡ßá‡¶∞ ‡¶¨‡¶Ø‡¶º‡¶∏ ‡¶ï‡¶§ ‡¶õ‡¶ø‡¶≤? ‡¶ï ‡ß®‡ßß ‡¶¨‡¶õ‡¶∞ ‡¶ñ ‡ß®‡ß© ‡¶¨‡¶õ‡¶∞ ‡¶ó ‡ß®‡ß´ ‡¶¨‡¶õ‡¶∞ ‡ß™‡ß≠‡•§ ‡¶ó‡¶ú‡¶æ‡¶®‡¶®‡ßá‡¶∞ ‡¶Æ‡¶æ‡¶Ø...\n",
      "  - ID: 103, Score: 10.6941, Text: ‡¶≤‡¶® ‡ßØ ‡¶Ö‡¶®‡¶≤‡¶æ‡¶á‡¶® ‡¶¨‡ßç‡¶Ø‡¶æ‡¶ö ‡ß©‡ßØ‡•§ ‡¶è‡¶ñ‡¶æ‡¶®‡ßá ‡¶ú‡¶æ‡¶Ø‡¶º‡¶ó‡¶æ ‡¶Ü‡¶õ‡ßá ‡¶â‡¶ï‡ßç‡¶§‡¶ø‡¶ü‡¶ø ‡¶ï‡¶æ‡¶∞? ‡¶ï ‡¶Ü‡¶∞‡ßç‡¶¶‡¶æ‡¶≤‡¶ø‡¶∞ ‡¶ñ ‡¶ó‡¶æ‡¶∞‡ßç‡¶°‡ßá‡¶∞ ‡¶ó ‡¶ï‡¶≤‡ßç‡¶Ø‡¶æ‡¶£‡ßÄ‡¶∞ ‡ß™‡ß¶‡•§ ‡¶∏‡ßç‡¶ü‡ßá‡¶∂‡¶®‡ßá ‡¶Ö‡¶®‡ßÅ‡¶™...\n",
      "  - ID: 2, Score: 6.0146, Text: ‡¶§‡¶æ‡¶∞ ‡¶ï ‡¶™‡ßç‡¶∞‡¶§‡¶ø‡¶™‡¶§‡ßç‡¶§‡¶ø ‡¶ñ ‡¶™‡ßç‡¶∞‡¶≠‡¶æ‡¶¨ ‡¶ó ‡¶¨‡¶ø‡¶ö‡¶ï‡ßç‡¶∑‡¶£‡¶§‡¶æ ‡¶ò ‡¶ï‡ßÅ‡¶ü ‡¶¨‡ßÅ‡¶¶‡ßç‡¶ß‡¶ø ‡¶®‡¶ø‡¶ö‡ßá‡¶∞ ‡¶Ö‡¶®‡ßÅ‡¶ö‡ßç‡¶õ‡ßá‡¶¶‡¶ü‡¶ø ‡¶™‡¶°‡¶º‡ßá ‡ß© ‡¶ì ‡ß™ ‡¶∏‡¶Ç‡¶ñ‡ßç‡¶Ø‡¶ï ‡¶™‡ßç‡¶∞‡¶∂‡ßç‡¶®‡ßá‡¶∞ ‡¶â‡¶§‡ßç‡¶§‡¶∞...\n",
      "  - ID: 3, Score: 5.9096, Text: ‡¶ì ‡ß´ ‡¶Ö‡¶®‡ßÅ‡¶™‡¶Æ‡ßá‡¶∞ ‡¶¨‡¶Ø‡¶º‡¶∏ ‡¶ï‡¶§ ‡¶¨‡¶õ‡¶∞? ‡¶ï ‡¶™‡¶Å‡¶ö‡¶ø‡¶∂ ‡¶ñ ‡¶õ‡¶æ‡¶¨‡¶ø‡¶¨‡¶ø‡¶∂ ‡¶ó ‡¶∏‡¶æ‡¶§‡¶æ‡¶∂ ‡¶ò ‡¶Ü‡¶ü‡¶æ‡¶∂...\n"
     ]
    }
   ],
   "source": [
    "keyword_search(\"‡¶Ö‡¶®‡ßÅ‡¶™‡¶Æ‡ßá‡¶∞ ‡¶≠‡¶æ‡¶∑‡¶æ‡¶Ø‡¶º ‡¶∏‡ßÅ‡¶™‡ßÅ‡¶∞‡ßÅ‡¶∑ ‡¶ï‡¶æ‡¶ï‡ßá ‡¶¨‡¶≤‡¶æ ‡¶π‡¶Ø‡¶º‡ßá‡¶õ‡ßá?\", top_k=5, num_candidates=15)\n",
    "keyword_search(\"‡¶ï‡¶æ‡¶ï‡ßá ‡¶Ö‡¶®‡ßÅ‡¶™‡¶Æ‡ßá‡¶∞ ‡¶≠‡¶æ‡¶ó‡ßç‡¶Ø ‡¶¶‡ßá‡¶¨‡¶§‡¶æ ‡¶¨‡¶≤‡ßá ‡¶â‡¶≤‡ßç‡¶≤‡ßá‡¶ñ ‡¶ï‡¶∞‡¶æ ‡¶π‡¶Ø‡¶º‡ßá‡¶õ‡ßá?\", top_k=5, num_candidates=15)\n",
    "keyword_search(\"‡¶¨‡¶ø‡¶Ø‡¶º‡ßá‡¶∞ ‡¶∏‡¶Æ‡¶Ø‡¶º ‡¶ï‡¶≤‡ßç‡¶Ø‡¶æ‡¶£‡ßÄ‡¶∞ ‡¶™‡ßç‡¶∞‡¶ï‡ßÉ‡¶§ ‡¶¨‡¶Ø‡¶º‡¶∏ ‡¶ï‡¶§ ‡¶õ‡¶ø‡¶≤?\", top_k=5, num_candidates=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "c4e86bb3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rerank results for query '‡¶Ö‡¶®‡ßÅ‡¶™‡¶Æ‡ßá‡¶∞ ‡¶≠‡¶æ‡¶∑‡¶æ‡¶Ø‡¶º ‡¶∏‡ßÅ‡¶™‡ßÅ‡¶∞‡ßÅ‡¶∑ ‡¶ï‡¶æ‡¶ï‡ßá ‡¶¨‡¶≤‡¶æ ‡¶π‡¶Ø‡¶º‡ßá‡¶õ‡ßá?':\n",
      "0 0.71113056 ‡¶≤‡ßÅ‡¶≤ ‡¶ú‡¶Ü‡¶≤‡¶≤‡¶æ‡¶á‡¶® ‡¶¨‡ßç‡¶Ø‡¶æ‡¶ö ‡ßß? ‡ß¨‡ßØ‡•§ ‡¶ï‡¶æ‡¶∞ ‡¶∏‡¶ô‡ßç‡¶ó‡ßá ‡¶™‡¶û‡ßç‡¶ö‡¶∂‡¶∞‡ßá‡¶∞ ‡¶¨‡¶ø‡¶∞‡ßã‡¶ß ‡¶®‡ßá‡¶á ‡¶¨‡¶≤‡ßá ‡¶Ö‡¶®‡ßÅ‡¶™‡¶Æ‡ßá‡¶∞ ‡¶Æ‡¶®‡ßá ‡¶π‡¶≤‡ßã? ‡¶ï ‡¶ó‡¶ú‡¶æ‡¶®‡¶®‡ßá‡¶∞ ‡¶ñ ‡¶ï‡¶æ‡¶∞‡ßç‡¶§‡¶ø‡¶ï‡ßá‡¶∞ ‡¶ó ‡¶™‡ßç‡¶∞‡¶ú‡¶æ‡¶™‡¶§‡¶ø‡¶∞ ‡¶ò ‡¶Ö‡¶®‡ßç‡¶®‡¶™‡ßÇ‡¶∞‡ßç‡¶£‡¶æ ‡ß≠‡ß¶‡•§ ‡¶∏‡ßÅ‡¶™‡ßÅ‡¶∞‡ßÅ‡¶∑ ‡¶¨‡¶ü‡ßá ‡¶ï‡ßá? ‡¶ï ‡¶Ö‡¶®‡ßÅ‡¶™‡¶Æ ‡¶ñ ‡¶π‡¶∞‡¶ø‡¶∂ ‡¶ó ‡¶Æ‡¶æ‡¶Æ‡¶æ ‡¶ò ‡¶∂‡¶∏‡ßç‡¶§‡ßÅ‡¶®‡¶æ‡¶• ‡ß≠‡ßß‡•§ ‡¶ö‡ßÅ‡¶≤ ‡¶ï‡¶æ‡¶ö‡¶æ ‡¶ó‡ßã‡¶Å‡¶´ ‡¶™‡¶æ‡¶ï ‡¶ß‡¶∞‡ßá‡¶õ‡ßá ‡¶ï‡¶æ‡¶∞? ‡¶ï ‡¶Æ‡¶æ‡¶Æ‡¶æ‡¶∞ ‡¶ñ ‡¶∂‡¶∏‡ßç‡¶§‡ßÅ‡¶®‡¶æ‡¶•‡ßá‡¶∞ ‡¶ó ‡¶¨‡¶ø‡¶®‡ßÅ‡¶¶‡¶æ‡¶¶‡¶æ‡¶∞ ‡¶ò ‡¶π‡¶∞‡¶ø‡¶∂‡ßá‡¶∞ ‡ß≠‡ß®‡•§ ‡¶ï‡¶≤‡ßç‡¶Ø‡¶æ‡¶£‡ßÄ ‡¶ï‡ßã‡¶® ‡¶∏‡ßç‡¶ü‡ßá‡¶∂‡¶® ‡¶®‡ßá‡¶Æ‡ßá ‡¶ó‡ßá‡¶≤? ‡¶ï ‡¶ï‡ßã‡¶®‡ßç‡¶®‡¶ó‡¶∞ ‡¶ñ ‡¶ï‡¶≤‡¶ø‡¶ï‡¶æ‡¶§‡¶æ ‡¶ó ‡¶ï‡¶æ‡¶®‡¶™‡ßÅ‡¶∞ ‡¶ò ‡¶π‡¶æ‡¶ì‡¶°‡¶º‡¶æ ‡ß≠‡ß©‡•§ ‡¶õ‡ßã‡¶ü‡¶¨‡ßá‡¶≤‡¶æ‡¶Ø‡¶º ‡¶™‡¶£‡ßç‡¶°‡¶ø‡¶§ ‡¶Æ‡¶∂‡¶æ‡¶Ø‡¶º ‡¶¨‡¶ø‡¶¶‡ßç‡¶∞‡¶™ ‡¶ï‡¶∞‡¶§ ‡¶ï‡ßá‡¶®? ‡¶ï ‡¶ï‡ßÅ‡ßé‡¶∏‡¶ø‡¶§ ‡¶è‡¶¨‡¶Ç ‡¶®‡¶ø‡¶ó‡ßç‡¶°‡¶£ ‡¶π‡¶ì‡¶Ø‡¶º‡¶æ‡¶∞ ‡¶ï‡¶æ‡¶∞‡¶£‡ßá ‡¶ñ ‡¶ï‡ßÅ‡ßé‡¶∏‡¶ø‡¶§ ‡¶π‡¶Ø‡¶º‡ßá ‡¶ó‡ßÅ‡¶£‡¶¨‡¶æ‡¶® ‡¶π‡¶ì‡¶Ø‡¶º‡¶æ‡¶∞ ‡¶ï‡¶æ‡¶∞‡¶£‡ßá ‡¶ó ‡¶∏‡ßÅ‡¶¶‡¶∞‡ßç‡¶∂‡¶® ‡¶è‡¶¨‡¶Ç ‡¶ó‡ßÅ‡¶£‡¶¨‡¶æ‡¶® ‡¶π‡¶ì‡¶Ø‡¶º‡¶æ‡¶∞ ‡¶ï‡¶æ‡¶∞‡¶£‡ßá ‡¶ò ‡¶∏‡ßÅ‡¶¶‡¶∞‡ßç‡¶∂‡¶® ‡¶π‡¶Ø‡¶º‡ßá‡¶ì ‡¶®‡¶ø‡¶∞‡ßç‡¶≠‡¶£ ‡¶π‡¶ì‡¶Ø‡¶º‡¶æ‡¶∞ ‡¶ï‡¶æ‡¶∞‡¶£‡ßá ‡ß≠‡ß™‡•§ ‡¶Ö‡¶®‡ßÅ‡¶™‡¶Æ‡¶ï‡ßá ‡¶¨‡¶ø‡¶¨‡¶æ‡¶π ‡¶Ü‡¶∏‡¶∞ ‡¶•‡ßá‡¶ï‡ßá ‡¶´‡¶ø‡¶∞‡¶ø‡¶Ø‡¶º‡ßá ‡¶¶‡ßá‡¶¨‡¶æ‡¶∞ ‡¶ï‡¶æ‡¶∞‡¶£ ‡¶ï‡ßÄ? ‡¶ï ‡¶Ö‡¶®‡ßÅ‡¶™‡¶Æ‡ßá‡¶∞ ‡¶¨‡ßç‡¶Ø‡¶ï‡ßç‡¶§‡¶ø‡¶§‡ßç‡¶¨‡¶π‡ßÄ‡¶®‡¶§‡¶æ‡¶∞ ‡¶ï‡¶æ‡¶∞‡¶£‡ßá ‡¶ñ ‡¶Æ‡¶æ‡¶Æ‡¶æ‡¶∞ ‡¶π‡ßÄ‡¶®‡¶Æ‡ßç‡¶Æ‡¶®‡ßç‡¶Ø‡¶§‡¶æ‡¶∞ ‡¶ï‡¶æ‡¶∞‡¶£‡ßá ‡¶ó ‡¶ó‡¶Ø‡¶º‡¶®‡¶æ ‡¶®‡¶ø‡¶Ø‡¶º‡ßá ‡¶Æ‡¶®‡ßã‡¶Æ‡¶æ‡¶≤‡¶ø‡¶®‡ßç‡¶Ø‡ßá‡¶∞ ‡¶ï‡¶æ‡¶∞‡¶£‡ßá ‡¶ò ‡¶ï‡¶®‡ßá‡¶∞ ‡¶¨‡¶æ‡¶¨‡¶æ‡¶∞ ‡¶Ü‡¶§‡ßç‡¶Æ‡¶ó‡¶∞‡¶ø‡¶Æ‡¶æ‡¶∞ ‡¶ï‡¶æ‡¶∞‡¶£‡ßá ‡ß≠‡ß´‡•§ ‡¶Ü‡¶Æ‡¶æ‡¶∞ ‡¶™‡ßÅ‡¶∞‡ßã‡¶™‡ßÅ‡¶∞‡¶ø ‡¶¨‡¶Ø‡¶º‡¶∏‡¶á ‡¶π‡¶≤‡ßã ‡¶®‡¶æ ‡¶ï‡¶•‡¶æ‡¶ü‡¶ø ‡¶¶‡ßç‡¶¨‡¶æ‡¶∞‡¶æ ‡¶ï‡ßÄ ‡¶¨‡ßã‡¶ù‡¶æ‡¶®‡ßã ‡¶π‡¶Ø‡¶º‡ßá‡¶õ‡ßá? ‡¶ï ‡¶§‡¶∞‡ßÅ‡¶£ ‡¶¨‡¶Ø‡¶º‡¶∏‡ßÄ ‡¶ñ ‡¶Ö‡¶™‡¶∞‡¶ø‡¶£‡¶§ ‡¶¨‡¶Ø‡¶º‡¶∏‡ßÄ ‡¶ó ‡¶Ö‡¶§‡¶ø ‡¶®‡¶ø‡¶∞‡ßç‡¶≠‡¶§‡¶∂‡ßÄ‡¶≤ ‡¶ò ‡¶ö‡¶ø‡¶®‡ßç‡¶§‡¶æ‡¶Ø‡¶º ‡¶Ö‡¶™‡¶∞‡¶ø‡¶£‡¶§ ‡ß≠‡ß¨‡•§ ‡¶§‡¶æ‡¶Æ‡¶æ‡¶ï‡¶ü‡ßÅ‡¶ï‡ßÅ ‡¶™‡¶∞‡ßç‡¶Ø‡¶®‡ßç‡¶§ ‡¶ñ‡¶æ‡¶á ‡¶®‡¶æ ‡¶â‡¶ï‡ßç‡¶§‡¶ø‡¶ü‡¶ø\n",
      "1 0.5515985 ‡¶≤‡ßÅ‡¶≤ ‡¶ú‡¶Ü‡¶≤‡¶≤‡¶æ‡¶á‡¶® ‡¶¨‡ßç‡¶Ø‡¶æ‡¶ö ‡ßß? ‡ß©‡ß¶‡•§ ‡¶Ü‡¶Æ‡¶æ‡¶∞ ‡¶Æ‡¶§‡ßã ‡¶Ö‡¶ï‡ßç‡¶∑‡¶Æ ‡¶¶‡ßÅ‡¶®‡¶ø‡¶Ø‡¶º‡¶æ‡¶Ø‡¶º ‡¶®‡¶æ‡¶á‡•§ ‡¶Ö‡¶®‡ßÅ‡¶™‡¶Æ‡ßá‡¶∞ ‡¶è‡¶á ‡¶â‡¶ï‡ßç‡¶§‡¶ø‡¶∞ ‡¶Æ‡¶ß‡ßç‡¶Ø ‡¶¶‡¶ø‡¶Ø‡¶º‡ßá ‡¶ï‡ßÄ ‡¶™‡ßç‡¶∞‡¶ï‡¶æ‡¶∂ ‡¶™‡ßá‡¶Ø‡¶º‡ßá‡¶õ‡ßá? ‡¶ï‡ßÅ ‡¶¨‡ßã‡ß®‡ß® ‡¶Ö‡¶®‡ßÅ‡¶∂‡ßã‡¶ö‡¶®‡¶æ ‡¶Ö‡¶∏‡¶π‡¶æ‡¶Ø‡¶º‡¶§‡ßç‡¶¨ ‡¶ï‡ßç‡¶∑‡ßã‡¶≠ ‡¶®‡¶ø‡¶ö‡ßá‡¶∞ ‡¶ï‡ßã‡¶®‡¶ü‡¶ø ‡¶∏‡¶†‡¶ø‡¶ï? ‡¶ï, ‡¶ñ‡•§, ‡¶ó , ‡¶ò‡•§, , ‡¶â‡¶§‡ßç‡¶§‡¶∞ ‡¶ó ‡ß©‡ßß‡•§ ‡¶Ö‡¶™‡¶∞‡¶ø‡¶ö‡¶ø‡¶§‡¶æ ‡¶ó‡¶≤‡ßç‡¶™‡ßá ‡¶∂‡¶∏‡ßç‡¶§‡ßÅ‡¶®‡¶æ‡¶• ‡¶ö‡¶∞‡¶ø‡¶§‡ßç‡¶∞‡ßá‡¶∞ ‡¶ú‡¶®‡ßç‡¶Ø ‡¶™‡ßç‡¶∞‡¶Ø‡ßã‡¶ú‡ßç‡¶Ø ‡¶ï‡ßÅ ‡¶¨‡ßã ‡ßß‡ß¨ ‡¶ö‡ßÅ‡¶™‡¶ö‡¶æ‡¶™, ‡¶ö‡ßÅ‡¶≤ ‡¶ï‡ßÄ‡¶ö‡¶æ, ‡¶≠‡¶æ‡¶∑‡¶æ ‡¶Ü‡¶Å‡¶ü ‡¶∏‡ßÅ‡¶™‡ßÅ‡¶∞‡ßÅ‡¶∑, ‡¶ö‡ßÅ‡¶™‡¶ö‡¶æ‡¶™, ‡¶ö‡ßÅ‡¶≤ ‡¶™‡¶æ‡¶ï‡¶æ ‡¶®‡¶ø‡¶ö‡ßá‡¶∞ ‡¶ï‡ßã‡¶®‡¶ü‡¶ø ‡¶∏‡¶†‡¶ø‡¶ï? ‡¶ï, ‡¶ñ‡•§, ‡¶ó , ‡¶ò‡•§, , ‡¶â‡¶§‡ßç‡¶§‡¶∞ ‡¶ï ‡¶â‡¶¶‡ßç‡¶¶‡ßÄ‡¶™‡¶ï‡¶ü‡¶ø ‡¶™‡¶°‡¶º‡ßá ‡ß©‡ß® ‡¶ì ‡ß©‡ß© ‡¶®‡¶Ç ‡¶™‡ßç‡¶∞‡¶∂‡ßç‡¶®‡ßá‡¶∞ ‡¶â‡¶§‡ßç‡¶§‡¶∞ ‡¶¶‡¶æ‡¶ì ‡¶∂‡¶æ‡¶ï‡¶ø‡¶≤ ‡¶∏‡¶æ‡¶π‡ßá‡¶¨ ‡¶∂‡¶ø‡¶ï‡ßç‡¶∑‡¶ø‡¶§ ‡¶Æ‡¶æ‡¶®‡ßÅ‡¶∑‡•§ ‡¶§‡¶æ‡¶∞ ‡¶Ü‡¶§‡ßç‡¶Æ‡¶∏‡¶Æ‡ßç‡¶Æ‡¶æ‡¶®‡¶¨‡ßã‡¶ß ‡¶™‡ßç‡¶∞‡¶ñ‡¶∞‡•§ ‡¶Æ‡ßá‡¶Ø‡¶º‡ßá ‡¶∂‡¶ø‡¶∞‡¶ø‡¶®‡ßá‡¶∞ ‡¶¨‡¶ø‡¶Ø‡¶º‡ßá‡¶§‡ßá ‡¶®‡¶ø‡¶ú‡ßá‡¶∞ ‡¶Ö‡¶®‡¶ø‡¶ö‡ßç‡¶õ‡¶æ ‡¶∏‡¶§‡ßç‡¶§‡ßá‡¶ì ‡¶∏‡¶æ‡¶ß‡ßç‡¶Ø‡¶æ‡¶®‡ßÅ‡¶∏‡¶æ‡¶∞‡ßá ‡¶¨‡¶∞‡¶™‡¶ï‡ßç‡¶∑‡ßá‡¶∞ ‡¶Ø‡ßå‡¶§‡ßÅ‡¶ï‡ßá‡¶∞ ‡¶¶‡¶æ‡¶¨‡¶ø ‡¶™‡ßÇ‡¶∞‡¶£ ‡¶ï‡¶∞‡¶§‡ßá ‡¶∞‡¶æ‡¶ú‡¶ø ‡¶π‡¶®‡•§ ‡¶ï‡¶ø‡¶®‡ßç‡¶§‡ßÅ ‡¶â‡¶ö‡ßç‡¶ö‡¶∂‡¶ø‡¶ï‡ßç‡¶∑‡¶ø‡¶§ ‡¶∂‡¶ø‡¶∞‡¶ø‡¶® ‡¶Ø‡ßå‡¶§‡ßÅ‡¶ï‡ßá ‡¶Ö‡¶∏‡¶Æ‡ßç‡¶Æ‡¶§‡¶ø ‡¶ú‡¶æ‡¶®‡¶ø‡¶Ø‡¶º‡ßá ‡¶è ‡¶¨‡¶ø‡¶Ø‡¶º‡ßá ‡¶™‡ßç‡¶∞‡¶§‡ßç‡¶Ø‡¶æ‡¶ñ‡ßç‡¶Ø‡¶æ‡¶® ‡¶ï‡¶∞‡ßá‡•§ ‡¶∏‡¶ø ‡¶¨‡ßã ‡ß®‡ß® ‡ß©‡ß®‡•§ ‡¶â‡¶¶‡ßç‡¶¶‡ßÄ‡¶™‡¶ï‡ßá‡¶∞ ‡¶∂‡¶æ‡¶ï‡¶ø‡¶≤ ‡¶∏‡¶æ‡¶π‡ßá‡¶¨ ‡¶Ö‡¶™‡¶∞‡¶ø‡¶ö‡¶ø‡¶§‡¶æ ‡¶ó‡¶≤‡ßç‡¶™‡ßá‡¶∞ ‡¶ï‡¶æ‡¶∞ ‡¶∏‡¶æ‡¶•‡ßá ‡¶§‡ßÅ‡¶≤‡¶®‡ßÄ‡¶Ø‡¶º? ‡¶ï ‡¶Ö‡¶®‡ßÅ‡¶™‡¶Æ‡ßá‡¶∞ ‡¶Æ‡¶æ‡¶Æ‡¶æ ‡¶ñ ‡¶Ö‡¶®‡ßÅ‡¶™‡¶Æ‡ßá‡¶∞ ‡¶Æ‡¶æ ‡¶ó ‡¶∂‡¶∏‡ßç‡¶§‡ßÅ‡¶®‡¶æ‡¶• ‡¶¨‡¶æ‡¶¨‡ßÅ ‡¶ò ‡¶π‡¶∞‡¶ø‡¶∂ ‡¶â‡¶§‡ßç‡¶§‡¶∞ ‡¶ó ‡ß©‡ß©‡•§ ‡¶∂‡¶ø‡¶∞‡¶ø‡¶®‡ßá‡¶∞ ‡¶∏‡¶æ‡¶•‡ßá ‡¶ï‡¶≤‡ßç‡¶Ø‡¶æ‡¶£‡ßÄ‡¶∞ ‡¶Æ‡¶ø‡¶≤ ‡¶ï‡ßã‡¶•‡¶æ‡¶Ø‡¶º? ‡¶¨‡¶æ‡¶¨‡¶æ‡¶∞ ‡¶Ü‡¶ú‡ßç‡¶û‡¶æ‡¶¨‡¶æ‡¶π‡ßÄ ‡¶®‡¶ø‡¶ö‡ßá‡¶∞ ‡¶ï‡ßã‡¶®‡¶ü‡¶ø ‡¶∏‡¶†‡¶ø‡¶ï? ‡¶ï, ‡¶ñ‡•§, ‡¶ó , ‡¶ò‡•§, , ‡¶â‡¶§‡ßç‡¶§‡¶∞ ‡¶ï ‡¶®‡¶ø‡¶ö‡ßá‡¶∞ ‡¶â‡¶¶‡ßç‡¶¶‡ßÄ‡¶™‡¶ï‡¶ü‡¶ø\n",
      "2 0.43510985 ‡¶≤‡ßÅ‡¶≤ ‡¶ú‡¶Ü‡¶≤‡¶≤‡¶æ‡¶á‡¶® ‡¶¨‡ßç‡¶Ø‡¶æ‡¶ö ‡ßß? ‡¶™‡¶æ‡¶† ‡¶™‡¶∞‡¶ø‡¶ö‡¶ø‡¶§‡¶ø ‡¶Ö‡¶™‡¶∞‡¶ø‡¶ö‡¶ø‡¶§‡¶æ ‡¶™‡ßç‡¶∞‡¶•‡¶Æ ‡¶™‡ßç‡¶∞‡¶ï‡¶æ‡¶∂‡¶ø‡¶§ ‡¶π‡¶Ø‡¶º ‡¶™‡ßç‡¶∞‡¶Æ‡¶• ‡¶ö‡ßå‡¶ß‡ßÅ‡¶∞‡ßÄ ‡¶∏‡¶Æ‡ßç‡¶™‡¶æ‡¶¶‡¶ø‡¶§ ‡¶Æ‡¶æ‡¶∏‡¶ø‡¶ï ‡¶∏‡¶¨‡ßÅ‡¶ú‡¶™‡¶§‡ßç‡¶∞ ‡¶™‡¶§‡ßç‡¶∞‡¶ø‡¶ï‡¶æ‡¶∞ ‡ßß‡ß©‡ß®‡ßß ‡¶¨‡¶ô‡ßç‡¶ó‡¶æ‡¶¨‡ßç‡¶¶‡ßá‡¶∞ ‡ßß‡ßØ‡ßß‡ß™ ‡¶ï‡¶æ‡¶∞‡ßç‡¶§‡¶ø‡¶ï ‡¶∏‡¶Ç‡¶ñ‡ßç‡¶Ø‡¶æ‡¶Ø‡¶º‡•§ ‡¶è‡¶ü‡¶ø ‡¶™‡ßç‡¶∞‡¶•‡¶Æ ‡¶ó‡ßç‡¶∞‡¶®‡ßç‡¶•‡¶≠‡ßÅ‡¶ï‡ßç‡¶§ ‡¶π‡¶Ø‡¶º ‡¶∞‡¶¨‡ßÄ‡¶®‡ßç‡¶¶‡ßç‡¶∞‡¶ó‡¶≤‡ßç‡¶™‡ßá‡¶∞ ‡¶∏‡¶Ç‡¶ï‡¶≤‡¶® ‡¶ó‡¶≤‡ßç‡¶™‡¶∏‡¶™‡ßç‡¶§‡¶ï‡¶è ‡¶è‡¶¨‡¶Ç ‡¶™‡¶∞‡ßá, ‡¶ó‡¶≤‡ßç‡¶™‡¶ó‡ßÅ‡¶ö‡ßç‡¶õ ‡¶§‡ßÉ‡¶§‡ßÄ‡¶Ø‡¶º ‡¶ñ‡¶£‡ßç‡¶°‡ßá ‡ßß‡ßØ‡ß®‡ß≠‡•§ ‡¶Ö‡¶™‡¶∞‡¶ø‡¶ö‡¶ø‡¶§‡¶æ ‡¶ó‡¶≤‡ßç‡¶™‡ßá ‡¶Ö‡¶™‡¶∞‡¶ø‡¶ö‡¶ø‡¶§‡¶æ ‡¶¨‡¶ø‡¶∂‡ßá‡¶∑‡¶£‡ßá‡¶∞ ‡¶Ü‡¶°‡¶º‡¶æ‡¶≤‡ßá ‡¶Ø‡ßá ‡¶¨‡¶≤‡¶ø‡¶∑‡ßç‡¶† ‡¶¨‡ßç‡¶Ø‡¶ï‡ßç‡¶§‡¶ø‡¶§‡ßç‡¶¨‡ßá‡¶∞ ‡¶Ö‡¶ß‡¶ø‡¶ï‡¶æ‡¶∞‡ßÄ ‡¶®‡¶æ‡¶∞‡ßÄ‡¶∞ ‡¶ï‡¶æ‡¶π‡¶ø‡¶®‡¶ø ‡¶¨‡¶∞‡ßç‡¶£‡¶ø‡¶§ ‡¶π‡¶Ø‡¶º‡ßá‡¶õ‡ßá, ‡¶§‡¶æ‡¶∞ ‡¶®‡¶æ‡¶Æ ‡¶ï‡¶≤‡ßç‡¶Ø‡¶æ‡¶£‡ßÄ‡•§ ‡¶Ö‡¶Æ‡¶æ‡¶®‡¶¨‡¶ø‡¶ï ‡¶Ø‡ßå‡¶§‡ßÅ‡¶ï ‡¶™‡ßç‡¶∞‡¶•‡¶æ‡¶∞ ‡¶®‡¶ø‡¶∞‡ßç‡¶Æ‡¶Æ ‡¶¨‡¶≤‡¶ø ‡¶π‡¶Ø‡¶º‡ßá‡¶õ‡ßá ‡¶è‡¶Æ‡¶® ‡¶®‡¶æ‡¶∞‡ßÄ‡¶¶‡ßá‡¶∞ ‡¶ó‡¶≤‡ßç‡¶™ ‡¶á‡¶§‡¶É‡¶™‡ßÇ‡¶∞‡ßç‡¶¨‡ßá ‡¶∞‡¶ö‡¶®‡¶æ ‡¶ï‡¶∞‡ßá‡¶õ‡¶ø‡¶≤‡ßá‡¶® ‡¶∞‡¶¨‡ßÄ‡¶®‡ßç‡¶¶‡ßç‡¶∞‡¶®‡¶æ‡¶•‡•§ ‡¶ï‡¶ø‡¶®‡ßç‡¶§‡ßÅ ‡¶è‡¶á ‡¶ó‡¶≤‡ßç‡¶™‡ßá‡¶á ‡¶™‡ßç‡¶∞‡¶•‡¶Æ ‡¶Ø‡ßå‡¶§‡ßÅ‡¶ï ‡¶™‡ßç‡¶∞‡¶•‡¶æ‡¶∞ ‡¶¨‡¶ø‡¶∞‡ßÅ‡¶¶‡ßç‡¶ß‡ßá ‡¶®‡¶æ‡¶∞‡ßÄ‡¶™‡ßÅ‡¶∞‡ßÅ‡¶∑‡ßá‡¶∞ ‡¶∏‡¶Æ‡ßç‡¶Æ‡¶ø‡¶≤‡¶ø‡¶§ ‡¶™‡ßç‡¶∞‡¶§‡¶ø‡¶∞‡ßã‡¶ß‡ßá‡¶∞ ‡¶ï‡¶•‡¶ï‡¶§‡¶æ ‡¶∂‡ßã‡¶®‡¶æ‡¶≤‡ßá‡¶® ‡¶§‡¶ø‡¶®‡¶ø‡•§ ‡¶è ‡¶ó‡¶≤‡ßç‡¶™‡ßá ‡¶™‡¶ø‡¶§‡¶æ ‡¶∂‡¶∏‡ßç‡¶§‡ßÅ‡¶®‡¶æ‡¶• ‡¶∏‡ßá‡¶® ‡¶è‡¶¨‡¶Ç ‡¶ï‡¶®‡ßç‡¶Ø‡¶æ ‡¶ï‡¶≤‡ßç‡¶Ø‡¶æ‡¶£‡ßÄ‡¶∞ ‡¶∏‡ßç‡¶¨‡¶§‡¶®‡ßç‡¶§‡ßç‡¶∞‡¶¨‡ßÄ‡¶ï‡ßç‡¶∑‡¶æ ‡¶ì ‡¶Ü‡¶ö‡¶∞‡¶£‡ßá ‡¶∏‡¶Æ‡¶æ‡¶ú‡ßá ‡¶ó‡ßá‡¶°‡¶º‡ßá‡¶¨‡¶∏‡¶æ ‡¶ò‡ßÉ‡¶£‡ßç‡¶Ø ‡¶Ø‡ßå‡¶§‡ßÅ‡¶ï ‡¶™‡ßç‡¶∞‡¶•‡¶æ ‡¶™‡ßç‡¶∞‡¶§‡¶ø‡¶∞‡ßã‡¶ß‡ßá‡¶∞ ‡¶∏‡¶Æ‡ßç‡¶Æ‡ßÅ‡¶ñ‡ßÄ‡¶® ‡¶π‡¶Ø‡¶º‡ßá‡¶õ‡ßá‡•§ ‡¶™‡¶ø‡¶§‡¶æ‡¶∞ ‡¶¨‡¶≤‡¶ø‡¶∑‡ßç‡¶† ‡¶™‡ßç‡¶∞‡¶§‡¶ø‡¶∞‡ßã‡¶ß ‡¶è‡¶¨‡¶Ç ‡¶ï‡¶≤‡ßç‡¶Ø‡¶æ‡¶£‡ßÄ‡¶∞ ‡¶¶‡ßá‡¶∂‡¶ö‡ßá‡¶§‡¶®‡¶æ‡¶Ø‡¶º ‡¶ñ‡¶¶‡ßç‡¶ß ‡¶¨‡ßç‡¶Ø‡¶ï‡ßç‡¶§‡¶ø‡¶§‡ßç‡¶¨‡ßá‡¶∞ ‡¶ú‡¶æ‡¶ó‡¶∞‡¶£ ‡¶ì ‡¶§‡¶æ‡¶∞ ‡¶Ö‡¶≠‡¶ø‡¶¨‡ßç‡¶Ø‡¶ï‡ßç‡¶§‡¶ø‡¶§‡ßá ‡¶ó‡¶≤‡ßç‡¶™‡¶ü‡¶ø ‡¶∏‡ßç‡¶¨‡¶æ‡¶∞‡ßç‡¶•‡¶ï‡•§ ‡¶Ö‡¶™‡¶∞‡¶ø‡¶ö‡¶ø‡¶§‡¶æ ‡¶â‡¶§‡ßç‡¶§‡¶Æ ‡¶™‡ßÅ‡¶∞‡ßÅ‡¶∑‡ßá‡¶∞ ‡¶ú‡¶¨‡¶æ‡¶®‡¶ø‡¶§‡ßá ‡¶≤‡ßá‡¶ñ‡¶æ ‡¶ó‡¶≤‡ßç‡¶™‡•§ ‡¶ó‡¶≤‡ßç‡¶™‡ßá‡¶∞ ‡¶ï‡¶•‡¶ï ‡¶Ö‡¶®‡ßÅ‡¶™‡¶Æ ‡¶¨‡¶ø‡¶∂ ‡¶∂‡¶§‡¶ï‡ßá‡¶∞ ‡¶¶‡ßç‡¶¨‡¶ø‡¶§‡ßÄ‡¶Ø‡¶º ‡¶¶‡¶∂‡¶ï‡ßá‡¶∞ ‡¶Ø‡ßÅ‡¶¶‡ßç‡¶ß‡¶∏‡¶Ç‡¶≤‡¶ó‡ßç‡¶® ‡¶∏‡¶Æ‡¶Ø‡¶º‡ßá‡¶∞ ‡¶∏‡ßá‡¶á ‡¶¨‡¶æ‡¶ô‡¶æ‡¶≤‡¶ø ‡¶Ø‡ßÅ‡¶¨‡¶ï, ‡¶Ø‡ßá ‡¶¨‡¶ø‡¶∂‡ßç‡¶¨‡¶¨‡¶ø‡¶¶‡ßç‡¶Ø‡¶æ‡¶≤‡¶Ø‡¶º‡ßá‡¶∞ ‡¶â‡¶ö‡ßç‡¶ö‡¶§‡¶∞ ‡¶â‡¶™‡¶æ‡¶ß‡¶ø ‡¶Ö‡¶∞‡ßç‡¶ú‡¶® ‡¶ï‡¶∞‡ßá‡¶ì ‡¶¨‡ßç‡¶Ø‡¶ï‡ßç‡¶§‡¶ø‡¶§‡ßç‡¶¨‡¶∞‡¶π‡¶ø‡¶§, ‡¶™‡¶∞‡¶ø‡¶¨‡¶æ‡¶∞‡¶§‡¶®‡ßç‡¶§‡ßç‡¶∞‡ßá‡¶∞ ‡¶ï‡¶æ‡¶õ‡ßá ‡¶Ö‡¶∏‡¶π‡¶æ‡¶Ø‡¶º ‡¶™‡ßÅ‡¶§‡ßÅ‡¶≤‡¶Æ‡¶æ‡¶§‡ßç‡¶∞‡•§ ‡¶§‡¶æ‡¶ï‡ßá ‡¶¶‡ßá‡¶ñ‡¶≤‡ßá ‡¶Ü‡¶ú‡ßã ‡¶Æ‡¶®‡ßá ‡¶π‡¶Ø‡¶º, ‡¶∏‡ßá ‡¶Ø‡ßá‡¶® ‡¶Æ‡¶æ‡¶Ø‡¶º‡ßá‡¶∞ ‡¶ï‡ßã‡¶≤‡¶∏‡¶Ç‡¶≤‡¶ó‡ßç‡¶® ‡¶∂‡¶ø‡¶∂‡ßÅ‡¶Æ‡¶æ‡¶§‡ßç‡¶∞‡•§ ‡¶§‡¶æ‡¶∞‡¶á ‡¶¨‡¶ø‡¶Ø‡¶º‡ßá\n"
     ]
    }
   ],
   "source": [
    "query = \"‡¶Ö‡¶®‡ßÅ‡¶™‡¶Æ‡ßá‡¶∞ ‡¶≠‡¶æ‡¶∑‡¶æ‡¶Ø‡¶º ‡¶∏‡ßÅ‡¶™‡ßÅ‡¶∞‡ßÅ‡¶∑ ‡¶ï‡¶æ‡¶ï‡ßá ‡¶¨‡¶≤‡¶æ ‡¶π‡¶Ø‡¶º‡ßá‡¶õ‡ßá?\"\n",
    "results = co.rerank(query=query, documents=chunk_texts, top_n=3, return_documents=True)\n",
    "print(f\"Rerank results for query '{query}':\")\n",
    "for idx, result in enumerate(results.results):\n",
    "    print(idx, result.relevance_score, result.document.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "id": "322a1958",
   "metadata": {},
   "outputs": [],
   "source": [
    "def keyword_and_rerank_search(query, top_k=5, num_candidates=15):\n",
    "    print(\"Input Query:\", query)\n",
    "\n",
    "    # Step 1: Keyword Search using BM25\n",
    "    bm25_scores = bm25.get_scores(bm25_tokenizer(query))\n",
    "    top_n = np.argpartition(bm25_scores, -num_candidates)[-num_candidates:]\n",
    "    bm25_hits = [{\n",
    "        'corpus_id': idx,\n",
    "        'score': bm25_scores[idx],\n",
    "        'text': chunk_texts[idx]\n",
    "    } for idx in top_n]\n",
    "    bm25_hits = sorted(bm25_hits, key=lambda x: x['score'], reverse=True)\n",
    "    \n",
    "    candidate_texts = [hit['text'] for hit in bm25_hits]\n",
    "\n",
    "    # Step 2: Reranking using Cohere\n",
    "    results = co.rerank(query=query, documents=candidate_texts, top_n=top_k, return_documents=True)\n",
    "\n",
    "    # Step 3: Print results\n",
    "    print(f\"\\nTop {top_k} reranked results for query '{query}':\")\n",
    "    for idx, result in enumerate(results.results):\n",
    "        print(f\"{idx + 1}. Relevance Score: {result.relevance_score:.4f}\")\n",
    "        print(f\"   Text: {result.document.text[:150]}...\\n\")\n",
    "\n",
    "    return [(result.document.text, result.relevance_score) for result in results.results]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "id": "2482b63c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input Query: ‡¶Ö‡¶®‡ßÅ‡¶™‡¶Æ‡ßá‡¶∞ ‡¶≠‡¶æ‡¶∑‡¶æ‡¶Ø‡¶º ‡¶∏‡ßÅ‡¶™‡ßÅ‡¶∞‡ßÅ‡¶∑ ‡¶ï‡¶æ‡¶ï‡ßá ‡¶¨‡¶≤‡¶æ ‡¶π‡¶Ø‡¶º‡ßá‡¶õ‡ßá?\n",
      "\n",
      "Top 3 reranked results for query '‡¶Ö‡¶®‡ßÅ‡¶™‡¶Æ‡ßá‡¶∞ ‡¶≠‡¶æ‡¶∑‡¶æ‡¶Ø‡¶º ‡¶∏‡ßÅ‡¶™‡ßÅ‡¶∞‡ßÅ‡¶∑ ‡¶ï‡¶æ‡¶ï‡ßá ‡¶¨‡¶≤‡¶æ ‡¶π‡¶Ø‡¶º‡ßá‡¶õ‡ßá?':\n",
      "1. Relevance Score: 0.7111\n",
      "   Text: ‡¶≤‡ßÅ‡¶≤ ‡¶ú‡¶Ü‡¶≤‡¶≤‡¶æ‡¶á‡¶® ‡¶¨‡ßç‡¶Ø‡¶æ‡¶ö ‡ßß? ‡ß¨‡ßØ‡•§ ‡¶ï‡¶æ‡¶∞ ‡¶∏‡¶ô‡ßç‡¶ó‡ßá ‡¶™‡¶û‡ßç‡¶ö‡¶∂‡¶∞‡ßá‡¶∞ ‡¶¨‡¶ø‡¶∞‡ßã‡¶ß ‡¶®‡ßá‡¶á ‡¶¨‡¶≤‡ßá ‡¶Ö‡¶®‡ßÅ‡¶™‡¶Æ‡ßá‡¶∞ ‡¶Æ‡¶®‡ßá ‡¶π‡¶≤‡ßã? ‡¶ï ‡¶ó‡¶ú‡¶æ‡¶®‡¶®‡ßá‡¶∞ ‡¶ñ ‡¶ï‡¶æ‡¶∞‡ßç‡¶§‡¶ø‡¶ï‡ßá‡¶∞ ‡¶ó ‡¶™‡ßç‡¶∞‡¶ú‡¶æ‡¶™‡¶§‡¶ø‡¶∞ ‡¶ò ‡¶Ö‡¶®‡ßç‡¶®‡¶™‡ßÇ‡¶∞‡ßç‡¶£‡¶æ ‡ß≠‡ß¶‡•§ ‡¶∏‡ßÅ‡¶™‡ßÅ‡¶∞‡ßÅ‡¶∑ ‡¶¨‡¶ü‡ßá ‡¶ï‡ßá? ‡¶ï ‡¶Ö‡¶®‡ßÅ‡¶™‡¶Æ ...\n",
      "\n",
      "2. Relevance Score: 0.5516\n",
      "   Text: ‡¶≤‡ßÅ‡¶≤ ‡¶ú‡¶Ü‡¶≤‡¶≤‡¶æ‡¶á‡¶® ‡¶¨‡ßç‡¶Ø‡¶æ‡¶ö ‡ßß? ‡ß©‡ß¶‡•§ ‡¶Ü‡¶Æ‡¶æ‡¶∞ ‡¶Æ‡¶§‡ßã ‡¶Ö‡¶ï‡ßç‡¶∑‡¶Æ ‡¶¶‡ßÅ‡¶®‡¶ø‡¶Ø‡¶º‡¶æ‡¶Ø‡¶º ‡¶®‡¶æ‡¶á‡•§ ‡¶Ö‡¶®‡ßÅ‡¶™‡¶Æ‡ßá‡¶∞ ‡¶è‡¶á ‡¶â‡¶ï‡ßç‡¶§‡¶ø‡¶∞ ‡¶Æ‡¶ß‡ßç‡¶Ø ‡¶¶‡¶ø‡¶Ø‡¶º‡ßá ‡¶ï‡ßÄ ‡¶™‡ßç‡¶∞‡¶ï‡¶æ‡¶∂ ‡¶™‡ßá‡¶Ø‡¶º‡ßá‡¶õ‡ßá? ‡¶ï‡ßÅ ‡¶¨‡ßã‡ß®‡ß® ‡¶Ö‡¶®‡ßÅ‡¶∂‡ßã‡¶ö‡¶®‡¶æ ‡¶Ö‡¶∏‡¶π‡¶æ‡¶Ø‡¶º‡¶§‡ßç‡¶¨ ‡¶ï‡ßç‡¶∑‡ßã‡¶≠ ‡¶®‡¶ø‡¶ö‡ßá‡¶∞ ‡¶ï‡ßã‡¶®‡¶ü‡¶ø ‡¶∏‡¶†...\n",
      "\n",
      "3. Relevance Score: 0.2761\n",
      "   Text: ‡¶Æ‡¶®‡ßç‡¶¶ ‡¶®‡¶Ø‡¶º ‡¶π‡ßá! ‡¶ñ‡¶æ‡¶ü‡¶ø ‡¶∏‡ßã‡¶®‡¶æ ‡¶¨‡¶ü‡ßá! ‡¶¨‡¶ø‡¶®‡ßÅ‡¶¶‡¶æ‡¶¶‡¶æ‡¶∞ ‡¶≠‡¶æ‡¶∑‡¶æ‡¶ü‡¶æ ‡¶Ö‡¶§‡ßç‡¶Ø‡¶®‡ßç‡¶§ ‡¶Ü‡¶Å‡¶ü‡•§ ‡¶Ø‡ßá‡¶ñ‡¶æ‡¶®‡ßá ‡¶Ü‡¶Æ‡¶∞‡¶æ ‡¶¨‡¶≤‡¶ø ‡¶ö‡¶Æ‡ßé‡¶ï‡¶æ‡¶∞ ‡¶∏‡ßá‡¶ñ‡¶æ‡¶®‡ßá ‡¶§‡¶ø‡¶®‡¶ø ‡¶¨‡¶≤‡ßá‡¶® ‡¶ö‡¶≤‡¶®‡¶∏‡¶á‡•§ ‡¶Ö‡¶§‡¶è‡¶¨ ‡¶¨‡ßÅ‡¶ù‡¶ø‡¶≤‡¶æ‡¶Æ, ‡¶Ü‡¶Æ‡¶æ‡¶∞ ‡¶≠‡¶æ‡¶ó‡ßç‡¶Ø‡ßá ‡¶™‡ßç‡¶∞‡¶ú‡¶æ‡¶™‡¶§‡¶ø‡¶∞ ‡¶∏‡¶ô‡ßç‡¶ó‡ßá ‡¶™‡¶û‡ßç...\n",
      "\n"
     ]
    }
   ],
   "source": [
    "query = \"‡¶Ö‡¶®‡ßÅ‡¶™‡¶Æ‡ßá‡¶∞ ‡¶≠‡¶æ‡¶∑‡¶æ‡¶Ø‡¶º ‡¶∏‡ßÅ‡¶™‡ßÅ‡¶∞‡ßÅ‡¶∑ ‡¶ï‡¶æ‡¶ï‡ßá ‡¶¨‡¶≤‡¶æ ‡¶π‡¶Ø‡¶º‡ßá‡¶õ‡ßá?\"\n",
    "top_docs = keyword_and_rerank_search(query, top_k=3, num_candidates=15)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "id": "ea188da1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain.embeddings.cohere import CohereEmbeddings\n",
    "from langchain.chat_models import ChatCohere\n",
    "from langchain.schema import HumanMessage\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.memory import ConversationBufferWindowMemory\n",
    "from langchain.schema import Document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "id": "eeddf39e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FAISS index saved to 'faiss_index/'\n"
     ]
    }
   ],
   "source": [
    "# Use MPS device for HuggingFace embeddings (Apple Silicon GPU)\n",
    "from langchain_huggingface import HuggingFaceEmbeddings\n",
    "from langchain.schema import Document\n",
    "\n",
    "device = \"mps\"  # Apple Silicon GPU\n",
    "\n",
    "embedding_model = HuggingFaceEmbeddings(\n",
    "    model_name=\"sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2\",\n",
    "    model_kwargs={\"device\": device}\n",
    ")\n",
    "\n",
    "docs = [Document(page_content=chunk['text']) for chunk in chunks]\n",
    "faiss_store = FAISS.from_documents(docs, embedding=embedding_model)\n",
    "faiss_store.save_local(\"../faiss_index\")\n",
    "print(\"FAISS index saved to 'faiss_index/'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "id": "716103b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Faiss load local\n",
    "faiss_store = FAISS.load_local(\n",
    "    \"../faiss_index\",\n",
    "    embeddings=embedding_model,\n",
    "    allow_dangerous_deserialization=True\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "id": "5794fce4",
   "metadata": {},
   "outputs": [],
   "source": [
    "template = \"\"\"‡¶™‡ßç‡¶∞‡¶∏‡¶ô‡ßç‡¶ó:\n",
    "‡¶®‡¶ø‡¶ö‡ßá ‡¶è‡¶ï‡¶ü‡¶ø ‡¶Ö‡¶ú‡¶æ‡¶®‡¶æ ‡¶ß‡¶∞‡¶®‡ßá‡¶∞ ‡¶§‡¶•‡ßç‡¶Ø‡¶∏‡ßÇ‡¶§‡ßç‡¶∞ (context) ‡¶™‡ßç‡¶∞‡¶¶‡¶æ‡¶® ‡¶ï‡¶∞‡¶æ ‡¶π‡¶Ø‡¶º‡ßá‡¶õ‡ßá‡•§ ‡¶è‡¶ü‡¶ø ‡¶è‡¶ï‡¶ü‡¶ø ‡¶ó‡¶≤‡ßç‡¶™, ‡¶™‡ßç‡¶∞‡¶∂‡ßç‡¶®‡ßã‡¶§‡ßç‡¶§‡¶∞, ‡¶¨‡¶π‡ßÅ ‡¶®‡¶ø‡¶∞‡ßç‡¶¨‡¶æ‡¶ö‡¶®‡ßÄ ‡¶™‡ßç‡¶∞‡¶∂‡ßç‡¶®, ‡¶∏‡¶æ‡¶ß‡¶æ‡¶∞‡¶£ ‡¶ú‡ßç‡¶û‡¶æ‡¶®, ‡¶Ü‡¶≤‡ßã‡¶ö‡¶®‡¶æ ‡¶Ö‡¶•‡¶¨‡¶æ ‡¶Ö‡¶®‡ßç‡¶Ø ‡¶Ø‡ßá‡¶ï‡ßã‡¶®‡ßã ‡¶ß‡¶∞‡¶£‡ßá‡¶∞ ‡¶≤‡ßá‡¶ñ‡¶æ ‡¶π‡¶§‡ßá ‡¶™‡¶æ‡¶∞‡ßá‡•§ \n",
    "‡¶è‡¶á ‡¶§‡¶•‡ßç‡¶Ø‡¶∏‡ßÇ‡¶§‡ßç‡¶∞‡ßá‡¶∞ ‡¶≠‡¶ø‡¶§‡¶∞‡ßá ‡¶¨‡¶æ ‡¶∂‡ßá‡¶∑‡ßá ‡¶ï‡¶ø‡¶õ‡ßÅ ‡¶™‡ßç‡¶∞‡¶∂‡ßç‡¶®‡ßá‡¶∞ ‡¶∏‡¶†‡¶ø‡¶ï ‡¶â‡¶§‡ßç‡¶§‡¶∞ ‡¶∏‡¶∞‡¶æ‡¶∏‡¶∞‡¶ø ‡¶¨‡¶æ ‡¶™‡¶∞‡ßã‡¶ï‡ßç‡¶∑‡¶≠‡¶æ‡¶¨‡ßá ‡¶â‡¶™‡¶∏‡ßç‡¶•‡¶ø‡¶§ ‡¶•‡¶æ‡¶ï‡¶§‡ßá ‡¶™‡¶æ‡¶∞‡ßá ‚Äî ‡¶Ø‡ßá‡¶Æ‡¶® ‡¶∂‡ßá‡¶∑‡ßá ‡¶∏‡¶†‡¶ø‡¶ï ‡¶â‡¶§‡ßç‡¶§‡¶∞ ‡¶§‡¶æ‡¶≤‡¶ø‡¶ï‡¶æ‡¶¨‡¶¶‡ßç‡¶ß ‡¶•‡¶æ‡¶ï‡¶§‡ßá ‡¶™‡¶æ‡¶∞‡ßá (‡¶Ø‡ßá‡¶Æ‡¶®: \"Correct Answers\", \"Answer Key\" ‡¶á‡¶§‡ßç‡¶Ø‡¶æ‡¶¶‡¶ø), ‡¶Ö‡¶•‡¶¨‡¶æ ‡¶â‡¶§‡ßç‡¶§‡¶∞‡¶ó‡ßÅ‡¶≤‡ßã ‡¶≤‡ßá‡¶ñ‡¶æ‡¶∞ ‡¶≠‡¶ø‡¶§‡¶∞‡ßá ‡¶õ‡¶°‡¶º‡¶ø‡¶Ø‡¶º‡ßá ‡¶•‡¶æ‡¶ï‡¶§‡ßá ‡¶™‡¶æ‡¶∞‡ßá‡•§\n",
    "\n",
    "‡¶Ü‡¶™‡¶®‡¶æ‡¶∞ ‡¶ï‡¶æ‡¶ú:\n",
    "- ‡¶™‡ßÅ‡¶∞‡ßã ‡¶§‡¶•‡ßç‡¶Ø‡¶∏‡ßÇ‡¶§‡ßç‡¶∞ (context) ‡¶Æ‡¶®‡ßã‡¶Ø‡ßã‡¶ó ‡¶¶‡¶ø‡¶Ø‡¶º‡ßá ‡¶™‡¶°‡¶º‡ßÅ‡¶®‡•§\n",
    "- ‡¶™‡ßç‡¶∞‡¶¶‡¶§‡ßç‡¶§ ‡¶™‡ßç‡¶∞‡¶∂‡ßç‡¶®‡ßá‡¶∞ ‡¶∏‡¶†‡¶ø‡¶ï ‡¶â‡¶§‡ßç‡¶§‡¶∞ ‡¶§‡¶•‡ßç‡¶Ø‡¶∏‡ßÇ‡¶§‡ßç‡¶∞ ‡¶•‡ßá‡¶ï‡ßá ‡¶ñ‡ßÅ‡¶Å‡¶ú‡ßá ‡¶¨‡ßá‡¶∞ ‡¶ï‡¶∞‡ßÅ‡¶®‡•§\n",
    "- ‡¶Ø‡¶¶‡¶ø ‡¶∏‡¶†‡¶ø‡¶ï ‡¶â‡¶§‡ßç‡¶§‡¶∞ context-‡¶è‡¶∞ ‡¶∂‡ßá‡¶∑‡ßá ‡¶Ü‡¶≤‡¶æ‡¶¶‡¶æ‡¶≠‡¶æ‡¶¨‡ßá ‡¶§‡¶æ‡¶≤‡¶ø‡¶ï‡¶æ‡¶≠‡ßÅ‡¶ï‡ßç‡¶§ ‡¶•‡¶æ‡¶ï‡ßá, ‡¶§‡¶æ‡¶π‡¶≤‡ßá ‡¶∏‡ßá‡¶ñ‡¶æ‡¶® ‡¶•‡ßá‡¶ï‡ßá‡¶ì ‡¶Æ‡¶ø‡¶≤‡¶ø‡¶Ø‡¶º‡ßá ‡¶¶‡ßá‡¶ñ‡ßÅ‡¶®‡•§\n",
    "- ‡¶∏‡¶†‡¶ø‡¶ï ‡¶â‡¶§‡ßç‡¶§‡¶∞‡¶ü‡¶ø ‡¶∏‡¶Ç‡¶ï‡ßç‡¶∑‡¶ø‡¶™‡ßç‡¶§‡¶≠‡¶æ‡¶¨‡ßá ‡¶è‡¶¨‡¶Ç ‡¶∏‡ßç‡¶™‡¶∑‡ßç‡¶ü‡¶≠‡¶æ‡¶¨‡ßá ‡¶è‡¶ï ‡¶≤‡¶æ‡¶á‡¶®‡ßá ‡¶™‡ßç‡¶∞‡¶¶‡¶æ‡¶® ‡¶ï‡¶∞‡ßÅ‡¶®‡•§\n",
    "\n",
    "‡¶â‡¶§‡ßç‡¶§‡¶∞ ‡¶≤‡ßá‡¶ñ‡¶æ‡¶∞ ‡¶®‡¶ø‡¶Ø‡¶º‡¶Æ:\n",
    "- ‡¶Ü‡¶™‡¶®‡¶æ‡¶∞ ‡¶â‡¶§‡ßç‡¶§‡¶∞ ‡¶Ö‡¶¨‡¶∂‡ßç‡¶Ø‡¶á ‡¶§‡¶•‡ßç‡¶Ø‡¶∏‡ßÇ‡¶§‡ßç‡¶∞‡ßá‡¶∞ ‡¶â‡¶™‡¶∞ ‡¶≠‡¶ø‡¶§‡ßç‡¶§‡¶ø ‡¶ï‡¶∞‡ßá ‡¶π‡¶§‡ßá ‡¶π‡¶¨‡ßá‡•§\n",
    "- ‡¶Ö‡¶™‡ßç‡¶∞‡¶æ‡¶∏‡¶ô‡ßç‡¶ó‡¶ø‡¶ï ‡¶¨‡ßç‡¶Ø‡¶æ‡¶ñ‡ßç‡¶Ø‡¶æ ‡¶¨‡¶æ ‡¶Ö‡¶§‡¶ø‡¶∞‡¶ø‡¶ï‡ßç‡¶§ ‡¶ï‡¶ø‡¶õ‡ßÅ ‡¶Ø‡ßÅ‡¶ï‡ßç‡¶§ ‡¶ï‡¶∞‡¶¨‡ßá‡¶® ‡¶®‡¶æ‡•§\n",
    "- ‡¶™‡ßç‡¶∞‡¶∂‡ßç‡¶® ‡¶Ø‡ßá‡¶≠‡¶æ‡¶¨‡ßá‡¶á ‡¶π‡ßã‡¶ï, ‡¶Ü‡¶™‡¶®‡¶ø ‡¶ï‡ßá‡¶¨‡¶≤‡¶Æ‡¶æ‡¶§‡ßç‡¶∞ ‡¶∏‡¶Ç‡¶∂‡ßç‡¶≤‡¶ø‡¶∑‡ßç‡¶ü ‡¶ì ‡¶∏‡¶†‡¶ø‡¶ï ‡¶â‡¶§‡ßç‡¶§‡¶∞‡¶ü‡¶ø ‡¶è‡¶ï ‡¶≤‡¶æ‡¶á‡¶®‡ßá ‡¶¶‡¶ø‡¶®‡•§\n",
    "\n",
    "{context}\n",
    "\n",
    "‡¶™‡ßç‡¶∞‡¶∂‡ßç‡¶®: {question}\n",
    "‡¶â‡¶§‡ßç‡¶§‡¶∞: ‡¶è‡¶ï ‡¶≤‡¶æ‡¶á‡¶®‡ßá ‡¶∏‡¶†‡¶ø‡¶ï ‡¶â‡¶§‡ßç‡¶§‡¶∞ ‡¶¶‡¶ø‡¶®‡•§\"\"\"\n",
    "prompt_template = PromptTemplate(\n",
    "    input_variables=[\"context\", \"question\"],\n",
    "    template=template,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "id": "ae8e8cbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "memory = ConversationBufferWindowMemory(k=2, return_messages=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "id": "ebeb2b16",
   "metadata": {},
   "outputs": [],
   "source": [
    "openai_api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "llm_openai = ChatOpenAI(\n",
    "    openai_api_key=openai_api_key,\n",
    "    model=\"gpt-4o\",       \n",
    "    streaming=True       \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "id": "9dc34c61",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rag_chat_with_memory(query: str, llm):\n",
    "    # Save user question into memory\n",
    "    memory.chat_memory.add_user_message(query)\n",
    "\n",
    "    # Step 1: FAISS retrieval of top-10 candidate docs\n",
    "    retriever = faiss_store.as_retriever(search_kwargs={\"k\": 10})\n",
    "    candidate_docs = retriever.invoke(query)\n",
    "    \n",
    "    # Extract texts and indices from FAISS results\n",
    "    candidate_texts = [doc.page_content for doc in candidate_docs]\n",
    "    \n",
    "    # Step 2: Apply BM25 on the FAISS-retrieved documents\n",
    "    # Tokenize query for BM25\n",
    "    tokenized_query = bm25_tokenizer(query)\n",
    "    \n",
    "    # Create local BM25 index for the candidate texts\n",
    "    tokenized_candidates = [bm25_tokenizer(text) for text in candidate_texts]\n",
    "    local_bm25 = BM25Okapi(tokenized_candidates)\n",
    "    \n",
    "    # Get BM25 scores for candidate documents\n",
    "    bm25_scores = local_bm25.get_scores(tokenized_query)\n",
    "    \n",
    "    # Combine texts with their BM25 scores\n",
    "    bm25_results = [{\n",
    "        'text': text,\n",
    "        'score': score\n",
    "    } for text, score in zip(candidate_texts, bm25_scores)]\n",
    "    \n",
    "    # Sort by BM25 scores (descending)\n",
    "    bm25_results = sorted(bm25_results, key=lambda x: x['score'], reverse=True)\n",
    "    \n",
    "    # Step 3: Rerank BM25-ordered texts with Cohere to get top-3\n",
    "    rerank_res = co.rerank(\n",
    "        query=query,\n",
    "        documents=[res['text'] for res in bm25_results],\n",
    "        top_n=3,\n",
    "        return_documents=True\n",
    "    )\n",
    "    \n",
    "    # Step 4: Extract top reranked texts\n",
    "    top_texts = [res.document.text for res in rerank_res.results]\n",
    "    \n",
    "    # Step 5: Build context from reranked texts\n",
    "    context = \"\\n\".join(top_texts)\n",
    "\n",
    "    # Step 6: Generate answer using prompt template\n",
    "    prompt_str = prompt_template.format(context=context, question=query)\n",
    "    answer = llm.invoke([HumanMessage(content=prompt_str)]).content.strip()\n",
    "    \n",
    "    # Save answer into memory\n",
    "    memory.chat_memory.add_ai_message(answer)\n",
    "    \n",
    "    # Print and return\n",
    "    print(\"User:\", query)\n",
    "    print(\"Answer:\", answer)\n",
    "    return answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "id": "fd9f328d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_cohere import ChatCohere\n",
    "\n",
    "llm_command_r = ChatCohere(cohere_api_key=cohere_token, model=\"command-r\", streaming=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "id": "b38af656",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User: ‡¶¨‡¶ø‡¶Ø‡¶º‡ßá‡¶∞ ‡¶∏‡¶Æ‡¶Ø‡¶º ‡¶ï‡¶≤‡ßç‡¶Ø‡¶æ‡¶£‡ßÄ‡¶∞ ‡¶™‡ßç‡¶∞‡¶ï‡ßÉ‡¶§ ‡¶¨‡¶Ø‡¶º‡¶∏ ‡¶ï‡¶§ ‡¶õ‡¶ø‡¶≤?\n",
      "Answer: ‡¶§‡¶•‡ßç‡¶Ø‡¶∏‡ßÇ‡¶§‡ßç‡¶∞‡ßá ‡¶ï‡¶≤‡ßç‡¶Ø‡¶æ‡¶£‡ßÄ‡¶∞ ‡¶™‡ßç‡¶∞‡¶ï‡ßÉ‡¶§ ‡¶¨‡¶Ø‡¶º‡¶∏ ‡¶â‡¶≤‡ßç‡¶≤‡ßá‡¶ñ ‡¶ï‡¶∞‡¶æ ‡¶π‡¶Ø‡¶º‡¶®‡¶ø‡•§\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'‡¶§‡¶•‡ßç‡¶Ø‡¶∏‡ßÇ‡¶§‡ßç‡¶∞‡ßá ‡¶ï‡¶≤‡ßç‡¶Ø‡¶æ‡¶£‡ßÄ‡¶∞ ‡¶™‡ßç‡¶∞‡¶ï‡ßÉ‡¶§ ‡¶¨‡¶Ø‡¶º‡¶∏ ‡¶â‡¶≤‡ßç‡¶≤‡ßá‡¶ñ ‡¶ï‡¶∞‡¶æ ‡¶π‡¶Ø‡¶º‡¶®‡¶ø‡•§'"
      ]
     },
     "execution_count": 183,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rag_chat_with_memory(query=\"‡¶¨‡¶ø‡¶Ø‡¶º‡ßá‡¶∞ ‡¶∏‡¶Æ‡¶Ø‡¶º ‡¶ï‡¶≤‡ßç‡¶Ø‡¶æ‡¶£‡ßÄ‡¶∞ ‡¶™‡ßç‡¶∞‡¶ï‡ßÉ‡¶§ ‡¶¨‡¶Ø‡¶º‡¶∏ ‡¶ï‡¶§ ‡¶õ‡¶ø‡¶≤?\", llm=llm_openai) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "id": "4d6d38f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User: ‡¶¨‡¶ø‡¶Ø‡¶º‡ßá‡¶∞ ‡¶∏‡¶Æ‡¶Ø‡¶º ‡¶ï‡¶≤‡ßç‡¶Ø‡¶æ‡¶£‡ßÄ‡¶∞ ‡¶™‡ßç‡¶∞‡¶ï‡ßÉ‡¶§ ‡¶¨‡¶Ø‡¶º‡¶∏ ‡¶ï‡¶§ ‡¶õ‡¶ø‡¶≤?\n",
      "Answer: ‡ßß‡ßÆ\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'‡ßß‡ßÆ'"
      ]
     },
     "execution_count": 184,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rag_chat_with_memory(query=\"‡¶¨‡¶ø‡¶Ø‡¶º‡ßá‡¶∞ ‡¶∏‡¶Æ‡¶Ø‡¶º ‡¶ï‡¶≤‡ßç‡¶Ø‡¶æ‡¶£‡ßÄ‡¶∞ ‡¶™‡ßç‡¶∞‡¶ï‡ßÉ‡¶§ ‡¶¨‡¶Ø‡¶º‡¶∏ ‡¶ï‡¶§ ‡¶õ‡¶ø‡¶≤?\", llm=llm_command_r) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "id": "fd371883",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[HumanMessage(content='‡¶¨‡¶ø‡¶Ø‡¶º‡ßá‡¶∞ ‡¶∏‡¶Æ‡¶Ø‡¶º ‡¶ï‡¶≤‡ßç‡¶Ø‡¶æ‡¶£‡ßÄ‡¶∞ ‡¶™‡ßç‡¶∞‡¶ï‡ßÉ‡¶§ ‡¶¨‡¶Ø‡¶º‡¶∏ ‡¶ï‡¶§ ‡¶õ‡¶ø‡¶≤?'),\n",
       " AIMessage(content='‡¶§‡¶•‡ßç‡¶Ø‡¶∏‡ßÇ‡¶§‡ßç‡¶∞‡ßá ‡¶ï‡¶≤‡ßç‡¶Ø‡¶æ‡¶£‡ßÄ‡¶∞ ‡¶™‡ßç‡¶∞‡¶ï‡ßÉ‡¶§ ‡¶¨‡¶Ø‡¶º‡¶∏ ‡¶â‡¶≤‡ßç‡¶≤‡ßá‡¶ñ ‡¶ï‡¶∞‡¶æ ‡¶π‡¶Ø‡¶º‡¶®‡¶ø‡•§'),\n",
       " HumanMessage(content='‡¶¨‡¶ø‡¶Ø‡¶º‡ßá‡¶∞ ‡¶∏‡¶Æ‡¶Ø‡¶º ‡¶ï‡¶≤‡ßç‡¶Ø‡¶æ‡¶£‡ßÄ‡¶∞ ‡¶™‡ßç‡¶∞‡¶ï‡ßÉ‡¶§ ‡¶¨‡¶Ø‡¶º‡¶∏ ‡¶ï‡¶§ ‡¶õ‡¶ø‡¶≤?'),\n",
       " AIMessage(content='‡ßß‡ßÆ')]"
      ]
     },
     "execution_count": 185,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "memory.chat_memory.messages[-4:]  # Show last 2 messages in memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "id": "ef67351b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User: ‡¶Ö‡¶®‡ßÅ‡¶™‡¶Æ‡ßá‡¶∞ ‡¶≠‡¶æ‡¶∑‡¶æ‡¶Ø‡¶º ‡¶∏‡ßÅ‡¶™‡ßÅ‡¶∞‡ßÅ‡¶∑ ‡¶ï‡¶æ‡¶ï‡ßá ‡¶¨‡¶≤‡¶æ ‡¶π‡¶Ø‡¶º‡ßá‡¶õ‡ßá?\n",
      "Answer: ‡¶Ö‡¶®‡ßÅ‡¶™‡¶Æ‡ßá‡¶∞ ‡¶≠‡¶æ‡¶∑‡¶æ‡¶Ø‡¶º ‡¶∏‡ßÅ‡¶™‡ßÅ‡¶∞‡ßÅ‡¶∑‡¶ï‡ßá ‡¶¨‡¶≤‡¶æ ‡¶π‡¶Ø‡¶º‡ßá‡¶õ‡ßá '‡¶Æ‡¶æ‡¶Æ‡¶æ'‡•§\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"‡¶Ö‡¶®‡ßÅ‡¶™‡¶Æ‡ßá‡¶∞ ‡¶≠‡¶æ‡¶∑‡¶æ‡¶Ø‡¶º ‡¶∏‡ßÅ‡¶™‡ßÅ‡¶∞‡ßÅ‡¶∑‡¶ï‡ßá ‡¶¨‡¶≤‡¶æ ‡¶π‡¶Ø‡¶º‡ßá‡¶õ‡ßá '‡¶Æ‡¶æ‡¶Æ‡¶æ'‡•§\""
      ]
     },
     "execution_count": 186,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rag_chat_with_memory(query=\"‡¶Ö‡¶®‡ßÅ‡¶™‡¶Æ‡ßá‡¶∞ ‡¶≠‡¶æ‡¶∑‡¶æ‡¶Ø‡¶º ‡¶∏‡ßÅ‡¶™‡ßÅ‡¶∞‡ßÅ‡¶∑ ‡¶ï‡¶æ‡¶ï‡ßá ‡¶¨‡¶≤‡¶æ ‡¶π‡¶Ø‡¶º‡ßá‡¶õ‡ßá?\", llm=llm_openai) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "id": "2a977bac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User: ‡¶Ö‡¶®‡ßÅ‡¶™‡¶Æ‡ßá‡¶∞ ‡¶≠‡¶æ‡¶∑‡¶æ‡¶Ø‡¶º ‡¶∏‡ßÅ‡¶™‡ßÅ‡¶∞‡ßÅ‡¶∑ ‡¶ï‡¶æ‡¶ï‡ßá ‡¶¨‡¶≤‡¶æ ‡¶π‡¶Ø‡¶º‡ßá‡¶õ‡ßá?\n",
      "Answer: ‡¶∏‡ßÅ‡¶™‡ßÅ‡¶∞‡ßÅ‡¶∑ ‡¶Æ‡¶æ‡¶§‡ßÉ‡¶ï‡ßçÔøΩ‡ßá‡¶π‡¶ï‡ßá ‡¶¨‡¶≤‡¶æ ‡¶π‡¶Ø‡¶º‡ßá‡¶õ‡ßá‡•§\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'‡¶∏‡ßÅ‡¶™‡ßÅ‡¶∞‡ßÅ‡¶∑ ‡¶Æ‡¶æ‡¶§‡ßÉ‡¶ï‡ßçÔøΩ‡ßá‡¶π‡¶ï‡ßá ‡¶¨‡¶≤‡¶æ ‡¶π‡¶Ø‡¶º‡ßá‡¶õ‡ßá‡•§'"
      ]
     },
     "execution_count": 187,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rag_chat_with_memory(\"‡¶Ö‡¶®‡ßÅ‡¶™‡¶Æ‡ßá‡¶∞ ‡¶≠‡¶æ‡¶∑‡¶æ‡¶Ø‡¶º ‡¶∏‡ßÅ‡¶™‡ßÅ‡¶∞‡ßÅ‡¶∑ ‡¶ï‡¶æ‡¶ï‡ßá ‡¶¨‡¶≤‡¶æ ‡¶π‡¶Ø‡¶º‡ßá‡¶õ‡ßá?\", llm=llm_command_r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "id": "bb2c6396",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User: ‡¶ï‡¶æ‡¶ï‡ßá ‡¶Ö‡¶®‡ßÅ‡¶™‡¶Æ‡ßá‡¶∞ ‡¶≠‡¶æ‡¶ó‡ßç‡¶Ø ‡¶¶‡ßá‡¶¨‡¶§‡¶æ ‡¶¨‡¶≤‡ßá ‡¶â‡¶≤‡ßç‡¶≤‡ßá‡¶ñ ‡¶ï‡¶∞‡¶æ ‡¶π‡¶Ø‡¶º‡ßá‡¶õ‡ßá?\n",
      "Answer: ‡¶Æ‡¶¶‡¶®‡¶¶‡ßá‡¶¨‡¶ï‡ßá ‡¶Ö‡¶®‡ßÅ‡¶™‡¶Æ‡ßá‡¶∞ ‡¶≠‡¶æ‡¶ó‡ßç‡¶Ø ‡¶¶‡ßá‡¶¨‡¶§‡¶æ ‡¶¨‡¶≤‡ßá ‡¶â‡¶≤‡ßç‡¶≤‡ßá‡¶ñ ‡¶ï‡¶∞‡¶æ ‡¶π‡¶Ø‡¶º‡ßá‡¶õ‡ßá‡•§\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'‡¶Æ‡¶¶‡¶®‡¶¶‡ßá‡¶¨‡¶ï‡ßá ‡¶Ö‡¶®‡ßÅ‡¶™‡¶Æ‡ßá‡¶∞ ‡¶≠‡¶æ‡¶ó‡ßç‡¶Ø ‡¶¶‡ßá‡¶¨‡¶§‡¶æ ‡¶¨‡¶≤‡ßá ‡¶â‡¶≤‡ßç‡¶≤‡ßá‡¶ñ ‡¶ï‡¶∞‡¶æ ‡¶π‡¶Ø‡¶º‡ßá‡¶õ‡ßá‡•§'"
      ]
     },
     "execution_count": 188,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rag_chat_with_memory(query=\"‡¶ï‡¶æ‡¶ï‡ßá ‡¶Ö‡¶®‡ßÅ‡¶™‡¶Æ‡ßá‡¶∞ ‡¶≠‡¶æ‡¶ó‡ßç‡¶Ø ‡¶¶‡ßá‡¶¨‡¶§‡¶æ ‡¶¨‡¶≤‡ßá ‡¶â‡¶≤‡ßç‡¶≤‡ßá‡¶ñ ‡¶ï‡¶∞‡¶æ ‡¶π‡¶Ø‡¶º‡ßá‡¶õ‡ßá?\", llm=llm_openai) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "id": "8b7823b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User: ‡¶ï‡¶æ‡¶ï‡ßá ‡¶Ö‡¶®‡ßÅ‡¶™‡¶Æ‡ßá‡¶∞ ‡¶≠‡¶æ‡¶ó‡ßç‡¶Ø ‡¶¶‡ßá‡¶¨‡¶§‡¶æ ‡¶¨‡¶≤‡ßá ‡¶â‡¶≤‡ßç‡¶≤‡ßá‡¶ñ ‡¶ï‡¶∞‡¶æ ‡¶π‡¶Ø‡¶º‡ßá‡¶õ‡ßá?\n",
      "Answer: ‡¶á‡¶®‡¶ø‡•§\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'‡¶á‡¶®‡¶ø‡•§'"
      ]
     },
     "execution_count": 189,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rag_chat_with_memory(query=\"‡¶ï‡¶æ‡¶ï‡ßá ‡¶Ö‡¶®‡ßÅ‡¶™‡¶Æ‡ßá‡¶∞ ‡¶≠‡¶æ‡¶ó‡ßç‡¶Ø ‡¶¶‡ßá‡¶¨‡¶§‡¶æ ‡¶¨‡¶≤‡ßá ‡¶â‡¶≤‡ßç‡¶≤‡ßá‡¶ñ ‡¶ï‡¶∞‡¶æ ‡¶π‡¶Ø‡¶º‡ßá‡¶õ‡ßá?\", llm=llm_command_r)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv (3.12.7)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
